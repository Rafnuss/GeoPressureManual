[["index.html", "A User Manual for GeoPressureR Introduction 0.1 Geolocation by pressure 0.2 The GeoPressure suite 0.3 Installation", " A User Manual for GeoPressureR Introduction Understanding the temporal and spatial use of habitats by wildlife is crucial to apprehend ecological relationships in nature. Tracking small birds and bats requires tags of less than 2g, therefore lightweight geolocators are currently the most affordable and widespread option. Recent multi-sensor geolocators now capture accelerometer and pressure data in addition to light, offering new potential to refine the accuracy of bird positioning. In particular, as atmospheric pressure varies with space and time, pressure timeseries at a single location have a unique signature which can be used for global positioning independent of light recordings. 0.1 Geolocation by pressure The best introduction to geolocation by pressure is, in my opinion, to watch a video about it. Here is a 10min presentation which present the motivation, provides an overview of the method and illustrates some possible results. These two papers provide more detail on the method: Raphaël Nussbaumer, Mathieu Gravey, Martins Briedis, Felix Liechti. Global positioning with animal-borne pressure sensors, 14 June 2022, PREPRINT (Version 2) available at Research Square https://doi.org/10.21203/rs.3.rs-1381915/v2 Raphaël Nussbaumer, Mathieu Gravey, Martins Briedis, Felix Liechti. Inferring bird’s trajectory from multi-sensor geolocators and remote sensing with a graphical model, 25 May 2022, PREPRINT (Version 1) available at Research Square https://doi.org/10.21203/rs.3.rs-1693751/v1 0.2 The GeoPressure suite The GeoPressure suite includes several tools: GeoPressureR is the main R package which implements the full method and functionalities GeoPressureManual is the user guide developed to help you learn to use GeoPressureR GeoPressureTemplate is a template Github repository to help kickstart your project GeoPressureAPI is a JSON API that makes it easy to compute the mismatch of a geolocator pressure timeseries with the atmospheric pressure from ERA5 reanalysis data. This API is called directly by the functions geopressure_map() and geopressure_ts() in GeoPressureR, so you don’t have to worry about it. 0.3 Installation To start, install the GeoPressureR package from Github using the following line: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;Rafnuss/GeoPressureR&quot;) We will be needing some additional packages which can be installed from DESCRIPTION with devtools::install() Finally, we can load them with library(GeoPressureR) # Only used for some visualization. The code to compute the light position is included in `GeoPressureR` library(GeoLocTools) setupGeolocation() # ERA5 data download library library(ecmwfr) # Graph library library(igraph) # Plotting library library(ggplot2) library(gridExtra) library(plotly) library(RColorBrewer) # Interactif figure library library(leaflet) library(leaflet.extras) "],["pressure-map.html", "Chapter 1 Pressure map 1.1 Read geolocator data 1.2 Label tracks 1.3 Identify stationary periods 1.4 Compute mistmatch maps 1.5 Compute probability maps 1.6 Compute altitude 1.7 Compute pressure and altitude for the path 1.8 Save", " Chapter 1 Pressure map This chapter covers the main steps to determine the position of a bird from pressure data. This code basically implement the method presented in Nussbaumer et al. (2022a). 1.1 Read geolocator data We read the geolocator data and crop it so that it starts on the equipment date and ends on the retrieval date. pam &lt;- pam_read( pathname = &quot;data/0_PAM/18LX&quot;, crop_start = &quot;2017-06-20&quot;, crop_end = &quot;2018-05-02&quot; ) pam_read() currently support data from Swiss Ornithological Institute files (*.pressure, *.lux, *.acceleration) and Migrate Technology (.deg, *.lux). For other file format, please contact me (submit a Github issue or email). 1.2 Label tracks To ensure the high level of precision needed for the pressure match, we must manually edit the activity classification and the pressure timeseries to be matched. We suggest doing this with TRAINSET. Labelling tracks is dedicated to this exercise and includes tips and best practices. Here, we will just walk through the main step of the workflow. 1.2.1 Automatic classification of activity We initialize the labeling file with an automatic classification of activity. We first use a k-mean clustering to group periods of low and high activity and then classify high activities lasting more than 30 minutes as migratory activities. See more possible classifications in the PALMr manual. pam &lt;- pam_classify(pam, min_duration = 30) If your track has only pressure data and no acceleration data, see this gitub issue. 1.2.2 Edit activity on TRAINSET Use trainset_write() to export the automatically generated classifications in a csv file, which can be opened in TRAINSET: https://trainset.geocene.com/. trainset_write(pam, pathname = &quot;data/1_pressure/labels/&quot;) # browseURL(&quot;https://trainset.geocene.com/&quot;) Printscreen of the manual classification in TRAINSET. See Labelling tracks for more information. When you have finished the manual editing, export the new csv file (TRAINSET will add -labeled in the name) in /data/1_pressure/labels/) and read this file with trainset_read(). pam &lt;- trainset_read(pam, pathname = &quot;data/1_pressure/labels/&quot;) 1.3 Identify stationary periods Based on the activity labeling, pam_sta() creates a table of stationary periods as illustrated below. pam &lt;- pam_sta(pam) knitr::kable(head(pam$sta)) sta_id start end 1 2017-06-20 00:00:00 2017-08-04 19:50:00 2 2017-08-04 23:15:00 2017-08-05 19:30:00 3 2017-08-06 02:50:00 2017-08-06 19:15:00 4 2017-08-07 03:10:00 2017-08-07 19:15:00 5 2017-08-08 00:10:00 2017-08-29 18:40:00 6 2017-08-30 04:30:00 2017-08-30 18:45:00 We can visualize the pressure measurements for each grouped stationary period (symbolized by a different color). The back dots represents the pressure labeled as outliar and these datapoint will not be matched. pressure_na &lt;- pam$pressure pressure_na$obs[pressure_na$isoutliar | pressure_na$sta_id == 0] &lt;- NA p &lt;- ggplot() + geom_line(data = pam$pressure, aes(x = date, y = obs), col = &quot;grey&quot;) + geom_line(data = pressure_na, aes(x = date, y = obs, col = as.factor(sta_id))) + geom_point(data = subset(pam$pressure, isoutliar), aes(x = date, y = obs), colour = &quot;black&quot;) + theme_bw() + scale_y_continuous(name = &quot;Pressure (hPa)&quot;) + scale_colour_manual(values = rep(RColorBrewer::brewer.pal(9, &quot;Set1&quot;), times = 8)) ggplotly(p, dynamicTicks = T) %&gt;% layout( showlegend = F, legend = list(orientation = &quot;h&quot;, x = -0.5), yaxis = list(title = &quot;Pressure [hPa]&quot;) ) 1.4 Compute mistmatch maps Now that we have clean pressure timeseries for each stationary period, we are ready to match each one with atmospheric pressure data (ERA5). To overcome the challenge of computing mismatch on such a large dataset, this R package uses the API GeoPressure to perform the computation on Google Earth Engine. Initially, it is easier and faster to query only long stationary periods (in the example below, we select only periods longer than 12hrs). You can do so by setting the pressure of the stationary periods you wish to discard to NA. sta_id_keep &lt;- pam$sta$sta_id[difftime(pam$sta$end, pam$sta$start, units = &quot;hours&quot;) &gt; 0] pam$pressure$sta_id[!(pam$pressure$sta_id %in% sta_id_keep)] &lt;- NA We can now query the data on the API with geopressure_map(). A detailed description of the parameters can be found here. This will take a couple of minutes to run. pressure_maps &lt;- geopressure_map( pam$pressure, extent = c(50, -16, 0, 23), # coordinates of the map to request (N, W, S, E) scale = 2, # request on a 1/2=0.5° grid to make the code faster max_sample = 250, # limit the query to the first 250 datapoints. margin = 30 # roughly equivalent to 3hPa ) geopressure_map() returns a list of two rasters for each stationary periods. The first is the mean square error (\\(\\textbf{MSE}\\)) between the pressure timeseries and ERA5 map. The second (\\(\\textbf{z}_{thr}\\)) is the proportion of datapoints in the pressure timeseries which correspond to an altitude that falls between the min and max altitude of each grid cell. Read more about these values and how they are computed here. 1.5 Compute probability maps We then combine the two rasters in a single probability map using \\[\\textbf{P} = \\exp \\left(-w \\frac{\\textbf{MSE}}{s} \\right) [\\textbf{z}_{thr}&gt;thr]\\] where \\(s\\) is the standard deviation of pressure and \\(thr\\) is the threshold mask. Because the auto-correlation of the timeseries is not accounted for in this equation, we use a log-linear pooling weight \\(w=\\log(n) - 1\\), where \\(n\\) is the number of datapoints in the timeseries. Probability aggregation describing the influence of log-linear pooling and length of timeseries will be added later. pressure_prob &lt;- geopressure_prob_map( pressure_maps, s = 1, # standard deviation of pressure thr = 0.9 # threshold of the threshold proportion value acceptable ) We use leaflet to visualize the threshold mask, mismatch map, and overall probability map for a single stationary period. i_r &lt;- 2 leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() %&gt;% addRasterImage(pressure_prob[[i_r]], opacity = 0.8, colors = &quot;OrRd&quot;, group = &quot;Probability&quot;) %&gt;% addRasterImage(pressure_maps[[i_r]][[1]], opacity = 0.8, colors = &quot;OrRd&quot;, group = &quot;Mismatch&quot;) %&gt;% addRasterImage(pressure_maps[[i_r]][[2]], opacity = 0.8, colors = &quot;OrRd&quot;, group = &quot;Threashold&quot;) %&gt;% # addLegend(pal = pal, values = values(v[[i_s]][[3]]), title = &quot;Probability&quot;) %&gt;% addLayersControl( overlayGroups = c(&quot;Probability&quot;, &quot;Mismatch&quot;, &quot;Threashold&quot;), options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(c(&quot;Mismatch&quot;, &quot;Threashold&quot;)) We can also visualize the probability map for all stationary periods: li_s &lt;- list() l &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i_r in seq_len(length(pressure_prob))) { i_s &lt;- metadata(pressure_prob[[i_r]])$sta_id info &lt;- pam$sta[pam$sta$sta_id == i_s, ] info_str &lt;- paste0(i_s, &quot; | &quot;, format(info$start, &quot;%d-%b %H:%M&quot;), &quot;-&gt;&quot;, format(info$end, &quot;%d-%b %H:%M&quot;)) li_s &lt;- append(li_s, info_str) l &lt;- l %&gt;% addRasterImage(pressure_prob[[i_r]], opacity = 0.8, colors = &quot;OrRd&quot;, group = info_str) } l %&gt;% addLayersControl( overlayGroups = li_s, options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(tail(li_s, length(li_s) - 1)) 1.6 Compute altitude The second operation you can perform with GeoPressureR is to compute the exact altitude of the bird \\(z_{gl}\\) from its pressure measurement \\(P_{gl}\\) using the barometric equation, correcting for the natural variation of pressure and temperature. This function used is \\[ z_{gl}(x)=z_{ERA5}(x) + \\frac{T_{ERA5}(x)}{L_b} \\left( \\frac{P_{gl}}{P_{ERA5}(x)} \\right) ^{\\frac{RL_b}{g M}-1},\\] where \\(z_{ERA}\\), \\(T_{ERA}\\) and \\(P_{ERA}\\) respectively correspond to the ground level elevation, temperature at 2m and ground level pressure of ERA5, \\(L_b\\) is the standard temperature lapse rate, \\(R\\) is the universal gas constant, \\(g\\) is the gravity constant and \\(M\\) is the molar mass of air. See more information here. To illustrate the benefit of using this equation, we will compute the bird’s altitude for its first stationary period using (1) GeoPressureR and (2) the barometric equation using standard atmosphere condition. We first determine the position of the bird by using the most likely postion using geopressure_map2path pt &lt;- geopressure_map2path(pressure_prob[1]) And then call the function geopressure_ts() with the subset of pressure containing sta_id==1 pressure_timeserie_1 &lt;- geopressure_ts(pt$lon, pt$lat, pressure = subset(pam$pressure, sta_id == 1)) We can compare the altitude produced to the one computed without the correction for temperature and pressure: Lb &lt;- -0.0065 R &lt;- 8.31432 g0 &lt;- 9.80665 M &lt;- 0.0289644 T0 &lt;- 273.15 + 15 P0 &lt;- 1013.25 pressure_timeserie_1$altitude_baro &lt;- T0 / Lb * ((pressure_timeserie_1$pressure / P0)^(-R * Lb / g0 / M) - 1) and visualize this comparison: p &lt;- ggplot() + geom_line(data = as.data.frame(pressure_timeserie_1), aes(x = date, y = altitude, col = as.factor(&quot;Corrected elevation with ERA5&quot;))) + geom_line(data = as.data.frame(pressure_timeserie_1), aes(x = date, y = altitude_baro, col = as.factor(&quot;Uncorrected elevation&quot;))) + labs(col = &quot;&quot;) + theme_bw() ggplotly(p) %&gt;% layout(legend = list(orientation = &quot;h&quot;, x = -0.5)) The function geopressure_ts() also returns the ground level pressure timeseries from ERA5 at the location specified. This is useful to check whether there is a good match between the pressure measured by the geolocator and the one at the assumed location. This operation is typically used to check the quality of the manual labelling (see Labelling tracks). 1.7 Compute pressure and altitude for the path We can repeat the computation of the pressure timeserie for all stationary periods. First we compute all the most likely position from the probability map of pressure. path &lt;- geopressure_map2path(pressure_prob) Secondly, we can use geopressure_ts_path() which basically call geopressure_ts() in parallel for all stationary periods. We can additionally request to compute the altitude during the next flight flight with include_flight = c(0,1). Note that if a position of the path is over water, it will be moved to the closest point onshore. pressure_timeserie &lt;- geopressure_ts_path(path, pam$pressure, include_flight = c(0, 1)) p &lt;- ggplot() + geom_line(data = do.call(&quot;rbind&quot;, pressure_timeserie), aes(x = date, y = altitude)) + theme_bw() + scale_y_continuous(name = &quot;Altitude (m)&quot;) ggplotly(p, dynamicTicks = T) %&gt;% layout(showlegend = F) col &lt;- rep(RColorBrewer::brewer.pal(9, &quot;Set1&quot;), times = ceiling((nrow(pam$sta) + 1) / 9)) col &lt;- col[1:(nrow(pam$sta) + 1)] names(col) &lt;- levels(factor(c(0, pam$sta$sta_id))) p &lt;- ggplot() + geom_line(data = pam$pressure, aes(x = date, y = obs), colour = &quot;grey&quot;) + geom_point(data = subset(pam$pressure, isoutliar), aes(x = date, y = obs), colour = &quot;black&quot;) + # geom_line(data = pressure_na, aes(x = date, y = obs, color = factor(sta_id))) + geom_line(data = subset(do.call(&quot;rbind&quot;, pressure_timeserie), sta_id != 0), aes(x = date, y = pressure0, col = factor(sta_id))) + theme_bw() + scale_colour_manual(values = col) + scale_y_continuous(name = &quot;Pressure (hPa)&quot;) ggplotly(p, dynamicTicks = T) %&gt;% layout(showlegend = F) 1.8 Save save( pressure_timeserie, pressure_prob, pam, file = &quot;data/1_pressure/18LX_pressure_prob.Rdata&quot; ) References "],["light-map.html", "Chapter 2 Light map 2.1 Annotate twilights 2.2 Calibrate zenith angles 2.3 Compute stationary periods 2.4 Compute probability map 2.5 Save", " Chapter 2 Light map In this vignette, we use light data to estimate the position of the Great Reed Warbler (18LCX) at each stationary period. A more thorough introduction to geolocation with light data can be found on https://geolocationmanual.vogelwarte.ch/ (Lisovski et al. 2020). We first load the data generated in Pressure map. load(&quot;data/1_pressure/18LX_pressure_prob.Rdata&quot;) For the calibration of light data, we need additional information. The second calibration is so short (1 day) with 18LX, so we discard it in this example. lon_calib &lt;- 17.05 lat_calib &lt;- 48.9 tm_calib_1 &lt;- c(pam$sta$start[1], pam$sta$end[1]) # tm_calib_2 &lt;- c(pam$sta$start[nrow(pam$sta)], pam$sta$end[nrow(pam$sta)]) 2.1 Annotate twilights To find the time of twilight, we can use find_twilights(), a function performing the same task than TwGeos::FindTwilight(), but differently. By default, the threshold is the first and last of light day (i.e., pam$light$obs&gt;0). The shift_k argument is identical to the offset in GeoLight functions. shift_k &lt;- 0 twl &lt;- find_twilights(pam$light, shift_k = shift_k ) We can visualize the twilight with TwGeos functions. raw_geolight &lt;- data.frame( Date = pam$light$date, Light = pam$light$obs ) lightImage( tagdata = raw_geolight, offset = shift_k / 60 / 60 ) tsimagePoints(twl$twilight, offset = 0, pch = 16, cex = 1.2) tsimageDeploymentLines(raw_geolight$Date, lon = lon_calib, lat = lat_calib, offset = shift_k / 60 / 60, lwd = 3, col = adjustcolor(&quot;orange&quot;, alpha.f = 0.5) ) abline(v = tm_calib_1, lty = c(1, 2), col = &quot;firebrick&quot;, lwd = 1.5) If you notice any issue with the centering of the night in this figure, specify manually shift_k. The manual editing is easily performed with TRAINSET. In this case, we must label the datapoints we want to delete. Read more about TRAINSET labelling in Labelling tracks. We write the twilight data on a csv file which can be opened and edited in TRAINSET. write.csv( data.frame( series = ifelse(twl$rise, &quot;Rise&quot;, &quot;Set&quot;), timestamp = strftime(twl$twilight, &quot;%Y-%m-%dT00:00:00Z&quot;, tz = &quot;UTC&quot;), value = (as.numeric(format(twl$twilight, &quot;%H&quot;)) * 60 + as.numeric(format(twl$twilight, &quot;%M&quot;)) - shift_k / 60 + 60 * 12) %% (60 * 24), label = ifelse(is.null(twl$delete), &quot;&quot;, ifelse(twl$delete, &quot;Delete&quot;, &quot;&quot;)) ), file = &quot;data/2_light/labels/18LX_light.csv&quot;, row.names = FALSE ) # browseURL(&quot;https://trainset.geocene.com/&quot;) When the labeling is finished, export the file and update the deleted field in twl. csv &lt;- read.csv(paste0(&quot;data/2_light/labels/18LX_light-labeled.csv&quot;)) twl$deleted &lt;- !csv$label == &quot;&quot; lightImage(tagdata = raw_geolight, offset = 0) tsimagePoints(twl$twilight, offset = 0, pch = 16, cex = 1.2, col = ifelse(twl$deleted, &quot;grey20&quot;, ifelse(twl$rise, &quot;firebrick&quot;, &quot;cornflowerblue&quot;)) ) abline(v = tm_calib_1, lty = c(1, 2), col = &quot;firebrick&quot;, lwd = 1.5) 2.2 Calibrate zenith angles Instead of calibrating the twilight errors in terms of duration, we directly model the zenith angle error. First, we retrieve the twilight during the calibration period. twl_calib &lt;- subset(twl, !deleted &amp; twilight &gt;= tm_calib_1[1] &amp; twilight &lt;= tm_calib_1[2]) We then compute the zenith angle (i.e., elevation of the sun) of the twilight time at the calibration site. sun &lt;- solar(twl_calib$twilight) z &lt;- refracted(zenith(sun, lon_calib, lat_calib)) Finally, we fit a kernel distribution for a relatively smooth bandwidth to account for possible bias. fit_z &lt;- density(z, adjust = 1.4, from = 60, to = 120) hist(z, freq = F) lines(fit_z, col = &quot;red&quot;) The adjust parameter allows to manually set how smooth you want the fit to be. Because the zenith angle error model is fitted with data only at the calibration site and that we are using it for all locations of the bird’s journey, it is safer to assume a broader/smoother distribution. 2.3 Compute stationary periods Before computing the probability map, we group the twilights by stationary period using activity classify in Pressure map | Identifying stationary periods. tmp &lt;- which(mapply(function(start, end) { start &lt; twl$twilight &amp; twl$twilight &lt; end }, pam$sta$start, pam$sta$end), arr.ind = TRUE) twl$sta_id &lt;- 0 twl$sta_id[tmp[, 1]] &lt;- tmp[, 2] 2.4 Compute probability map We first define a grid on which to compute the probabilities. For ease of comparison with the pressure-derived map, we load the grid size and resolution from pressure_prob (computed Pressure map | Computing mistmatch maps g &lt;- as.data.frame(pressure_prob[[1]], xy = TRUE) g$layer &lt;- NA Selecting only the unlabelled twilights, we compute the probability of observing the zenith angle of each twilight using the calibrated error function for each grid cell. twl_clean &lt;- subset(twl, !deleted) sun &lt;- solar(twl_clean$twilight) pgz &lt;- apply(g, 1, function(x) { z &lt;- refracted(zenith(sun, x[1], x[2])) approx(fit_z$x, fit_z$y, z, yleft = 0, yright = 0)$y }) Aggregating the probability map of each twilight per stationary period requires some assumptions on the independence/correlation of the twilight errors. Read more about this in Probability aggregation. Here, we use a log-linear pooling with a weight of \\(w=0.1\\), w &lt;- 0.1 We loop through each stationary period and create a raster map with the aggregated probabilities. light_prob &lt;- c() for (i_s in seq_len(nrow(pam$sta))) { id &lt;- twl_clean$sta_id == pam$sta$sta_id[i_s] if (sum(id) &gt; 1) { g$layer &lt;- exp(colSums(w * log(pgz[id, ]))) # Log-linear equation express in log } else if (sum(id) == 1) { g$layer &lt;- pgz[id, ] } else { g$layer &lt;- 1 } gr &lt;- rasterFromXYZ(g) crs(gr) &lt;- &quot;+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0&quot; metadata(gr) &lt;- list( sta_id = pam$sta$sta_id[i_s], nb_sample = sum(id) ) light_prob[[i_s]] &lt;- gr } Finally, we can visualize the probability map for each stationary period. See code for figure li_s &lt;- list() l &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i_r in seq_len(length(light_prob))) { i_s &lt;- metadata(light_prob[[i_r]])$sta_id info &lt;- pam$sta[pam$sta$sta_id == i_s, ] info_str &lt;- paste0(i_s, &quot; | &quot;, info$start, &quot;-&gt;&quot;, info$end) li_s &lt;- append(li_s, info_str) l &lt;- l %&gt;% addRasterImage(light_prob[[i_r]], opacity = 0.8, colors = &quot;OrRd&quot;, group = info_str) } m &lt;- l %&gt;% addCircles(lng = lon_calib, lat = lat_calib, color = &quot;black&quot;, opacity = 1) %&gt;% addLayersControl( overlayGroups = li_s, options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(tail(li_s, length(li_s) - 1)) 2.5 Save save(twl, light_prob, z, fit_z, file = &quot;data/2_light/18LX_light_prob.Rdata&quot; ) References "],["static-map.html", "Chapter 3 Static map 3.1 Combine pressure and light 3.2 Check track with GeoPressureViz 3.3 Final checks 3.4 Save", " Chapter 3 Static map This chapter covers important pre-processing steps to ensure that modelling the trajectory with a graph is possible and successful. Firstly, we will aligned the maps of pressure and light and create a static_prob variable containing all the information necessary for modeling the trajectory (incl. flight info). But before moving too quickly, we need to carefully check that pressure, light and flight duration data allow for a coherent trajectory. It is possible (even probable) that some manual editing of the pressure data labeling will be required, especially for short stopovers. 3.1 Combine pressure and light Start by loading the data computed in Light map and Pressure map. load(&quot;data/1_pressure/18LX_pressure_prob.Rdata&quot;) load(&quot;data/2_light/18LX_light_prob.Rdata&quot;) We first need to retrieve the pressure and light data for the same stationary period. When running this code for the first time, it is recommended to start by keeping only long stationary periods (e.g. thr_sta_dur=5\\*24 hours), and when all the check below are passing, you can reduce this threshold to zero. thr_sta_dur &lt;- 0 # in hours sta_pres &lt;- unlist(lapply(pressure_prob, function(x) raster::metadata(x)$sta_id)) sta_light &lt;- unlist(lapply(light_prob, function(x) raster::metadata(x)$sta_id)) sta_thres &lt;- pam$sta$sta_id[difftime(pam$sta$end, pam$sta$start, units = &quot;hours&quot;) &gt; thr_sta_dur] # Get the sta_id present on all three data sources sta_id_keep &lt;- intersect(intersect(sta_pres, sta_light), sta_thres) # Filter pressure and light map pressure_prob &lt;- pressure_prob[sta_pres %in% sta_id_keep] light_prob &lt;- light_prob[sta_light %in% sta_id_keep] We then need to keep all the flights between consecutive stationary period separate so that we can estimate the wind support correctly. flight &lt;- list() for (i_f in seq_len(length(sta_id_keep) - 1)) { from_sta_id &lt;- sta_id_keep[i_f] to_sta_id &lt;- sta_id_keep[i_f + 1] flight[[i_f]] &lt;- list( start = pam$sta$end[seq(from_sta_id, to_sta_id - 1)], end = pam$sta$start[seq(from_sta_id + 1, to_sta_id)], sta_id = seq(from_sta_id, to_sta_id - 1) ) } flight[[i_f + 1]] &lt;- list() We compute the static probability with the product of light and pressure probability maps, and add the flight duration in the metadata. static_prob is the consolidate variable containing all the information necessary to run the graph functions. static_prob &lt;- mapply(function(light, pressure, flight) { # define static prob as the product of light and pressure prob static_prob &lt;- light * pressure # replace na by zero # tmp &lt;- values(static_prob) # tmp[is.na(tmp)] &lt;- 0 # values(static_prob) &lt;- tmp metadata(static_prob) &lt;- metadata(pressure) metadata(static_prob)$flight &lt;- flight return(static_prob) }, light_prob, pressure_prob, flight) We overwrite the probability of the first and last stationary periods with the known location of the equipment/retrieval sites. lon_calib &lt;- 17.05 lat_calib &lt;- 48.9 lat &lt;- seq(raster::ymax(static_prob[[1]]), raster::ymin(static_prob[[1]]), length.out = nrow(static_prob[[1]]) + 1) lat &lt;- lat[seq_len(length(lat) - 1)] + diff(lat[1:2]) / 2 lon &lt;- seq(raster::xmin(static_prob[[1]]), raster::xmax(static_prob[[1]]), length.out = ncol(static_prob[[1]]) + 1) lon &lt;- lon[seq_len(length(lon) - 1)] + diff(lon[1:2]) / 2 lon_calib_id &lt;- which.min(abs(lon_calib - lon)) lat_calib_id &lt;- which.min(abs(lat_calib - lat)) tmp &lt;- as.matrix(static_prob[[1]]) tmp[!is.na(tmp)] &lt;- 0 tmp[lat_calib_id, lon_calib_id] &lt;- 1 values(static_prob[[1]]) &lt;- tmp tmp &lt;- as.matrix(static_prob[[length(static_prob)]]) tmp[!is.na(tmp)] &lt;- 0 tmp[lat_calib_id, lon_calib_id] &lt;- 1 values(static_prob[[length(static_prob)]]) &lt;- tmp Finally, we can retrive the pressure and altitude from the most likely postion of the combined map of pressure and light. path &lt;- geopressure_map2path(static_prob) static_timeserie &lt;- geopressure_ts_path(path, pam$pressure) 3.2 Check track with GeoPressureViz Now that we have combine pressure and light, we need to verify that the data is coherent. This is a really important step, so bear with me here. In Labelling tracks, we had already checked that the pressure timeseries measured by the geolocator are consistent with a least one location on the map. But we didn’t checked that these position are (1) coherent with light data, and (2) within reach of one other considering the flight duration and realistic bird flight speed. To help you with this task, we have developed a shiny app GeoPressureViz which helps you visualize the overall trajectory of the bird as well as each step-by-step move. Screenshot of the GeoPressureViz demo showing the estimated position at one stationary period of the Great Reed Warbler 18LX, based on (1) the pressure and light match (map colorscale and timeserie) and (2) potential flight distances from previous and next stationary period (circles). 3.2.1 Navigate GeoPressureViz Open the demo for 18LX The viewer has three panels: The maps showing your the trajectory of the bird. The size of the circles indicates the duration of the stopover (hover over them to get more info). The bottom panel showing the pressure timeserie. The grey line is the raw day (pam$pressure), the black dots are pressure labeled as outliar, colored lines are the normalized pressure at the best match (i.e., static_timeserie$pressure0) and the color match the map dots. The side panel provides key information and helps you navigates the app A central parameter to play with carefully is the “Minimum duration”. This will filter the entire dataset and replot the map and figure to select only stopover of such duration or higher. Try changing this value once and wait a bit for the figure to update. As shorter stationary period are less certain, their position is often wrong. That’s ok for now. Toogle the “Full Track” button to move to the stationary period view. The side panel will change and provides you with more options. Change the stationary period with the drop down or previous/next button. Exept from the first sta., three dots, two lines and two circle will appears on the map, and the pressure timeserie will update to zoom exactly on this stationary period. The color of the timeserie informs you on which dots on the map is the current stationary period, the two others begin the previous and next one. The circles indicates the distance from and to the previous and last stationay period location based on the speed slider on the side pannel (default if 40km/h). You can edit the speed to see how this impact the distances. You can choose to display the probabily map of pressure (pressure_prob) , light (light_prob) or combines (static_prob). Because some location are completely off, it is helpful to change their location to check the coherence of distance with the next/previous stationary period. Use the button “Start Editing” to do that. Every time you will click on the map, it will update the position. Once you’re happy with the position, you can click again the button to disable the editing mode. Finally, you can update the pressure timeserie with the new position that you’ve edited with the button “Query pressure”. This runs pressure_ts on the background, so it will be slow (especially for long stationary period). This feature is quite unstable, so use carefully, and be aware that you might have to restart the app if it crashes. 3.2.2 Check your data With GeoPressureViz, we want to check that the probability map is coherent with the flight distance from the previous/next location. I suggest starting by selecting only long stopovers (24-72hours depending on your application), as this will help to draw out the general trajectory followed by the bird, and only later adding the shorter stopovers which could raise more confusion (the best match of pressure is often completely off). Following the same recommendation than in Labelling tracks, you want the non-outliar pressure of each stationary period to match a single elevation timeserie (bottom panel). You can check on the map that the pressure location seem coherent by selecting only “pressure” in the probability map display. Usually, it’s pretty obvious when there is an issue on the map. So, to correct any issue, go back to trainset and edit (1) labeling of activity to split or combine stationary periods and (2) labeling the pressure timeserie to exclude certain datapoints from the match. The good match of the timeserie is essential and will require several iteration. Some additional notes: - The distance is computed based on an assumed average groundspeed. Birds can fly with a groundspeed up to 120-150 km/h (with wind support) although their usual average is around 40km/h. - The default position of the bird in GeoPressureViz is based on the most likely position from the static probability map. This is (usually) not the correct location. - Bird tend to flight directly to their main destination. Most detour are artifact, or you really need a long stationary period with a good match of pressure. - The most regular issue I faced is a small vertical movement of the bird during a 2-8 days stopover. Shorter stopover are usually easy as the bird doesn’t move much but each species is different. 3.2.3 Run GeoPressureViz To run the visualization, you will need to save the data as ~/geopressureviz.RData (I cannot find a good way to pass variable to a shiny app instance, let me know if you have a suggestion). The minimum information needed is pam and static_prob, but to see the difference between light and pressure, you can also add light_prob and pressure_prob. To see the match of pressure timeserie in the bottom panel, add pressure_timeserie. geopressureviz &lt;- list( pam = pam, static_prob = static_prob, pressure_prob = pressure_prob, light_prob = light_prob, pressure_timeserie = static_timeserie ) save(geopressureviz, file = &quot;~/geopressureviz.RData&quot;) Run the app in the browser for best view with shiny::runApp(system.file(&quot;geopressureviz&quot;, package = &quot;GeoPressureR&quot;), launch.browser = getOption(&quot;browser&quot;)) 3.3 Final checks These checks are performed when creating the graph graph_create(), but for pedagogical reason, I thought it would be better to introduce them step by step here as they will also help you to get a better sense of the specific movement/trajectory of the bird you are modeling. 3.3.1 Check 1 A first and easy check is that there be at least one location with a probability greater than 1 for each stationary period. static_prob_n &lt;- lapply(static_prob, function(x) { probt &lt;- raster::as.matrix(x) probt[is.na(probt)] &lt;- 0 probt / sum(probt, na.rm = T) }) tmp &lt;- unlist(lapply(static_prob_n, sum)) == 0 if (any(tmp)) { warning(paste0( &quot;The `static_prob` provided has a probability map equal to &quot;, &quot;zero for the stationay period: &quot;, which(tmp) )) } 3.3.2 Check 2 Secondly, we check that there always be at least one possible transition from one stationary period to the next. for (i_s in seq_len(length(static_prob) - 1)) { cur &lt;- as.matrix(static_prob[[i_s]]) &gt; 0 cur[is.na(cur)] &lt;- F nex &lt;- as.matrix(static_prob[[i_s + 1]]) &gt; 0 nex[is.na(nex)] &lt;- F mtf &lt;- metadata(static_prob[[i_s]]) flight_duration &lt;- as.numeric(sum(difftime(mtf$flight$end, mtf$flight$start, unit = &quot;hours&quot;))) # hours resolution &lt;- mean(res(static_prob[[1]])) * 111 # assuming 1°= 111km thr_gs &lt;- 150 # Assuming a max groundspeed of 150km/h # Check possible position at next stationary period possible_next &lt;- (EBImage::distmap(!cur) * resolution / flight_duration) &lt; thr_gs if (sum(possible_next &amp; nex) == 0) { stop(paste(&quot;There are no possible transition from stationary period&quot;, i_s, &quot;to&quot;, i_s + 1, &quot;. Check part 1 process (light and pressure)&quot;, sep = &quot; &quot;)) } } 3.4 Save save(pam, static_prob, static_timeserie, file = &quot;data/3_static/18LX_static_prob.Rdata&quot; ) "],["basic-graph.html", "Chapter 4 Basic graph 4.1 Create the graph 4.2 Compute the transition probability 4.3 Output 1: Shortest path 4.4 Output 2: Marginal probability map 4.5 Output 3: Simulated paths 4.6 Save", " Chapter 4 Basic graph In this chapter, we will see how to create a mathematical graph to model the trajectory of the bird (Nussbaumer et al. 2022b). We will then use this graph to compute three main output: (1) the shortest path (i.e., the most likely trajectory, (2) the probability maps at each stationary period and (3) simulated paths sampled according to their likelihood. We called this a basic graph because it does not integrate windspeed, and make assumption on the groundspeed distribution of the bird. The chapte Wind graph will explain how we can retrieve wind data and improve the graph model. We already pre-processed the light and pressure data data in the chapter Static map. Make sure that the data was passing all the check before moving to this chapter load(&quot;data/3_static/18LX_static_prob.Rdata&quot;) To improve computational costs of creation of graph, it might be helpful to first run the model on a downscale resolution (fact &gt; 1) with the code below. We didn’t used this in our example. static_prob &lt;- lapply(static_prob, function(raster) { raster_ds &lt;- aggregate(raster, fact = 1, fun = max, na.rm = T, expand = T) # keep metadata metadata(raster_ds) &lt;- metadata(raster) return(raster_ds) }) 4.1 Create the graph We create the graph with the function graph_create(), which perform the following steps: We only keep the nodes of all locations within the 99% percentile of the static pressure map. (A node is uniquely identify by a latitude, longitude and stationary period). We only keep the nodes which are within reach of distance of all other nodes based on a average groundspeed of 150km/h. This accounts for the distance of all other possible nodes from the previous stationay period and to the next stationary period. This is computed with the image binary distance function distmap() from the EBImage package. This step allows to eliminate multiple impossible nodes without having to compute all possible transition. We then build the graph based on the filtered nodes and containing the edges requiring an average groundspeed less than 150km/h. Finally, we trim the graph based on the flow graph constraint, that is, the nodes must be connected to the equipment node and retrieval node. Indeed, after filtering, some nodes might be connected in a single direction (so called dead branch). We thus ensure that each node is on a path that connects the equipment site to the retrieval site. This operation is performed with the Breadth-first search (BFS) algorithm. The duration of this operation is strongly variable depending on the grid (resolution and size), the number of stationary periods and the level of contains from the static probability. grl &lt;- graph_create(static_prob, thr_prob_percentile = .99, thr_gs = 150 ) The graph returned is a list of the edges of the graph containing: s: source node (index in the 3d grid lat-lon-sta), t: target node (index in the 3d grid lat-lon-sta), gs:average ground speed required to make that transition (km/h) as complex number representing the E-W as real and S-N as imaginary. ps: static probability of each target node sz: size of the 3d grid lat-lon-sta equipement: node(s) of the first sta (index in the 3d grid lat-lon-sta) retrival: node(s) of the last sta (index in the 3d grid lat-lon-sta) flight_duration: list of flight duration to next sta in hours lat: list of the static_prob latitude in cell center lon: list of the static_prob longitude in cell center extent: raster geographical extent of the `static_prob`` resolution: raster res of the static_prob temporal_extent: start and end date time retrieved from the metadata of static_prob 4.2 Compute the transition probability We finally need to compute the probability of the transition represented by each edge of the graph. We use here a simple gamma distribution to model the probability of groundspeed. Because bird may flight back and forth over small distance, we give apparent groundspeed smaller than 20km/h the same probability than for 20 km/h. speed &lt;- seq(1, 120) low_speed_fix &lt;- 20 # minimum speed allowed prob &lt;- flight_prob(speed, method = &quot;gamma&quot;, shape = 7, scale = 7, low_speed_fix = low_speed_fix) plot(speed, prob, type = &quot;l&quot;, xlab = &quot;Groundspeed [km/h]&quot;, ylab = &quot;Probability&quot;) abline(v = low_speed_fix) grl$p &lt;- grl$ps * flight_prob(grl$gs, method = &quot;gamma&quot;, shape = 7, scale = 7, low_speed_fix = low_speed_fix) 4.3 Output 1: Shortest path In graph theory, the shortest path correspond to the set of nodes whose sum of the edges weights are as small as possible. By weighting the edges with the minus of the log of the probability, this corresponds to finding the most likely trajectory of our bird. We solve this problem with the igraph package g &lt;- graph_from_data_frame(data.frame( from = grl$s, to = grl$t, weight = -log(grl$p) )) # In case there are no retrival site, we select the position with the highest probability according to the marginal # retrival &lt;- which.max(as.matrix(static_prob_marginal[[length(static_prob_marginal)]])) + grl$sz[1] * grl$sz[2] * (grl$sz[3] - 1) sp &lt;- shortest_paths(g, from = paste(grl$equipement), to = paste(grl$retrival)) # Convert igraph representation to lat-lon shortest_path &lt;- graph_path2lonlat(as.numeric(sp$vpath[[1]]$name), grl) sta_duration &lt;- unlist(lapply(static_prob, function(x) { as.numeric(difftime(metadata(x)$temporal_extent[2], metadata(x)$temporal_extent[1], units = &quot;days&quot;)) })) leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() %&gt;% addPolylines(lng = shortest_path$lon, lat = shortest_path$lat, opacity = 1, color = &quot;#808080&quot;, weight = 3) %&gt;% addCircles(lng = shortest_path$lon, lat = shortest_path$lat, opacity = 1, color = &quot;#000&quot;, weight = sta_duration^(0.3) * 10) We retrieve the pressure and altitude for each stationary period at the most likely position. shortest_path_df &lt;- as.data.frame(shortest_path) shortest_path_timeserie &lt;- geopressure_ts_path(shortest_path_df, pam$pressure, include_flight = c(0, 1)) 4.4 Output 2: Marginal probability map Estimating the position of the bird for each stationary period is generally the most sought-after output of tracking studies. Using the graph built, we can compute this exactly (i.e., without iterative approach such as MCMC). This problem is the same as computing the marginal distribution of a Markov process which can be solved mathematically. static_prob_marginal &lt;- graph_marginal(grl) See code for figure li_s &lt;- list() l &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i_r in seq_len(length(static_prob_marginal))) { i_s &lt;- metadata(static_prob[[i_r]])$sta_id info &lt;- metadata(static_prob[[i_r]])$temporal_extent info_str &lt;- paste0(i_s, &quot; | &quot;, info[1], &quot;-&gt;&quot;, info[2]) li_s &lt;- append(li_s, info_str) l &lt;- l %&gt;% addRasterImage(static_prob_marginal[[i_r]], colors = &quot;OrRd&quot;, opacity = 0.8, group = info_str) %&gt;% addCircles(lng = shortest_path$lon[i_s], lat = shortest_path$lat[i_s], opacity = 1, color = &quot;#000&quot;, weight = 10, group = info_str) } m &lt;- l %&gt;% addLayersControl( overlayGroups = li_s, options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(tail(li_s, length(li_s) - 1)) 4.5 Output 3: Simulated paths We can compute a few simulation paths. Because they are independent and without error, so you don’t need many, although the computation to request more is almost the same as a few. nj &lt;- 10 # Number of simulation path_sim &lt;- graph_simulation(grl, nj = nj) See code for figure col &lt;- rep(RColorBrewer::brewer.pal(9, &quot;Set1&quot;), times = ceiling(grl$sz[3] / 9)) m &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i in seq_len(nj)) { m &lt;- m %&gt;% addPolylines(lng = path_sim$lon[i, ], lat = path_sim$lat[i, ], opacity = 0.7, weight = 1, color = &quot;#808080&quot;) } for (i in seq_len(grl$sz[3])) { m &lt;- m %&gt;% addCircles(lng = path_sim$lon[, i], lat = path_sim$lat[, i], opacity = .4, weight = 10, color = col[i]) } # m &lt;- m %&gt;% addLegend(position=&quot;bottomright&quot;, colors = col[1:grl$sz[3]], labels = seq_len(grl$sz[3]), title = &quot;Stationay period&quot;, opacity = 1 ) 4.6 Save save( # grl, we are excluding grl because of its size on this repo. Feel free to keep it in your own project path_sim, shortest_path, static_prob_marginal, shortest_path_timeserie, file = &quot;data/4_basic_graph/18LX_basic_graph.Rdata&quot; ) References "],["wind-graph.html", "Chapter 5 Wind graph 5.1 Download wind data 5.2 Create graph 5.3 Add wind to graph 5.4 Compute the transition probability 5.5 Output 1: Shortest path 5.6 Output 2: Marginal proability map 5.7 Output 3: Simulated paths 5.8 GeoPressureViz 5.9 Compute flight energy 5.10 Save", " Chapter 5 Wind graph In this final chapter, we will add wind data to the graph to refine the transition probability based on an assumed airspeed of the bird rather than groundspeed (Werfeli 2020). First load the static probability map. load(&quot;data/3_static/18LX_static_prob.Rdata&quot;) 5.1 Download wind data Wind data is available at high resolution (1hr, 0.25°, 37 pressure level) on ERA5 hourly data on pressure levels. And this data is easily accessible through the ecmwfr package. As the flight are of short duration, we suggest to download a file for each flight. The first step is to setup-up your CDS access. You will need to create an account on https://cds.climate.copernicus.eu/ to generate your API key and uid number. You can stored them in your .Rprofile with the commented code. Sys.setenv(cds_key = &quot;Insert_your_CDS_API_KEY_here&quot;) Sys.setenv(cds_user = &quot;Insert_your_CDS_UID_here&quot;) usethis::edit_r_environ() This will allow you to retrieve them whenever you need with cds_key &lt;- Sys.getenv(&quot;cds_key&quot;) cds_user &lt;- Sys.getenv(&quot;cds_user&quot;) wf_set_key(user = cds_user, key = cds_key, service = &quot;cds&quot;) To efficiently query only the data needed, we will sub-select the pressure level needed for each flight. We enter the 37 pressure level of ERA-5 and define the geographical area. possible_pressure &lt;- c(1, 2, 3, 5, 7, 10, 20, 30, 50, 70, seq(100, 250, 25), seq(300, 750, 50), seq(775, 1000, 25)) area &lt;- extent(static_prob[[1]]) area &lt;- c(area@ymax, area@xmin, area@ymin, area@xmax) It will be faster to send all the requests (one per flight) with wf_request() using transfer = F without waiting to get the data from one before requesting the next. These query can be very quick or sometime take a couple of hours, usually not more. You can monitor easily at https://cds.climate.copernicus.eu/cdsapp#!/yourrequests the status of your requests, delete them or download them manually if needed. req &lt;- list() for (i_s in seq_len(nrow(pam$sta) - 1)) { # Get the timeserie of the flight on a 1 hour resolution flight_time &lt;- seq(round(pam$sta$end[i_s] - 30 * 60, units = &quot;hours&quot;), round(pam$sta$start[i_s + 1] + 30 * 60, units = &quot;hours&quot;), by = 60 * 60) # Find the pressure level needed during this flight flight_id &lt;- flight_time[1] &lt;= pam$pressure$date &amp; pam$pressure$date &lt;= tail(flight_time, 1) pres_id_min &lt;- sum(!(min(pam$pressure$obs[flight_id]) &lt; possible_pressure)) pres_id_max &lt;- sum(max(pam$pressure$obs[flight_id]) &gt; possible_pressure) + 1 flight_pres_id &lt;- seq(pres_id_min, min(pres_id_max, length(possible_pressure))) # Prepare the query request &lt;- list( dataset_short_name = &quot;reanalysis-era5-pressure-levels&quot;, product_type = &quot;reanalysis&quot;, format = &quot;netcdf&quot;, variable = c(&quot;u_component_of_wind&quot;, &quot;v_component_of_wind&quot;), pressure_level = possible_pressure[flight_pres_id], year = sort(unique(format(flight_time, &quot;%Y&quot;))), month = sort(unique(format(flight_time, &quot;%m&quot;))), day = sort(unique(format(flight_time, &quot;%d&quot;))), time = sort(unique(format(flight_time, &quot;%H:%M&quot;))), # area is specified as N, W, S, E area = area ) # We can send the query without downloading the data. This allows to send all of them and then wait to get them back later. req[[i_s]] &lt;- wf_request(user = cds_user, request = request, transfer = F) } We suggest to save the wind data file in data/5_wind_graph/ dir_save &lt;- &quot;data/5_wind_graph/18LX&quot; dir.create(dir_save, showWarnings = F) The following code will return the status of the request if then have not yet been processed, or return the data otherwise. I suggest to check on [https://cds.climate.copernicus.eu/cdsapp#!/yourrequests] if the request have been completed before running this code. It can take a couple of minutes to a few hours. for (i_s in seq(1, length(req))) { filename &lt;- paste0(&quot;18LX_&quot;, i_s, &quot;.nc&quot;) wf_transfer(url = basename(req[[i_s]]$get_url()), service = &quot;cds&quot;, user = cds_user, path = dir_save, filename = filename) } 5.2 Create graph We first create the graph identically to in basic graph grl &lt;- graph_create(static_prob, thr_prob_percentile = .99, thr_gs = 150) 5.3 Add wind to graph We can compute the windspeed experienced by the bird if he had flew each possible transition (i.e. edge in the graph). Based on this windspeed and groundspeed, we also compute the airspeed. All of these are stored as complex value with the real part representing the E-W component and the imaginary part corresponding to the N-S. filename &lt;- paste0(dir_save, &quot;/&quot;, &quot;18IC_&quot;) grl &lt;- graph_add_wind(grl, pressure = pam$pressure, filename = &quot;data/5_wind_graph/18LX/18LX_&quot;, thr_as = 100) 5.4 Compute the transition probability Now that the have computed the airspeed required for performing the transition of each edge, we can improve the computation of the probability by modeling the probability of airspeed rather than groundspeed. We first search the morphological information of the Great Reed Warbler using the AVONET database. You can also overwrite any of these value if you know them. See flight_bird() for more details. bird &lt;- flight_bird(&quot;Acrocephalus arundinaceus&quot;) Using the bird created, we can convert a airspeed into a probability using the power method in the function flight_prob(). See Basic graph for more information on flight_prob(). As an example, we can plot the probability for an airspeed ranging between 0 and 80 km/h. speed &lt;- seq(0, 80) prob &lt;- flight_prob(speed, method = &quot;power&quot;, bird = bird, low_speed_fix = 10, fun_power = function(power) { (1 / power)^3 } ) plot(speed, prob, type = &quot;l&quot;, xlab = &quot;Airspeed [km/h]&quot;, ylab = &quot;Probability&quot;) We can then compute the probability of each transition of the graph. grl$p &lt;- grl$ps * flight_prob(grl$as, method = &quot;power&quot;, bird = bird, low_speed_fix = 10) 5.5 Output 1: Shortest path Same as Basic graph g &lt;- graph_from_data_frame(data.frame( from = grl$s, to = grl$t, weight = -log(grl$p) )) sp &lt;- shortest_paths(g, from = paste(grl$equipement), to = paste(grl$retrival)) # Convert igraph representation to lat-lon grl$shortest_path &lt;- graph_path2lonlat(as.numeric(sp$vpath[[1]]$name), grl) We can visualize the shortest path with the windpseed direction (arrow) and magnitude (color) experienced during this particular flight See code for figure fun_marker_color &lt;- function(norm) { if (norm &lt; 20) { &quot;darkpurple&quot; } else if (norm &lt; 35) { &quot;darkblue&quot; } else if (norm &lt; 50) { &quot;lightblue&quot; } else if (norm &lt; 60) { &quot;lightgreen&quot; } else if (norm &lt; 80) { &quot;yellow&quot; } else if (norm &lt; 100) { &quot;lightred&quot; } else { &quot;darkred&quot; } } fun_NSEW &lt;- function(angle) { angle &lt;- angle %% (pi * 2) angle &lt;- angle * 180 / pi if (angle &lt; 45 / 2) { &quot;E&quot; } else if (angle &lt; 45 * 3 / 2) { &quot;NE&quot; } else if (angle &lt; 45 * 5 / 2) { &quot;N&quot; } else if (angle &lt; 45 * 7 / 2) { &quot;NW&quot; } else if (angle &lt; 45 * 9 / 2) { &quot;W&quot; } else if (angle &lt; 45 * 11 / 2) { &quot;SW&quot; } else if (angle &lt; 45 * 13 / 2) { &quot;S&quot; } else if (angle &lt; 45 * 15 / 2) { &quot;SE&quot; } else { &quot;E&quot; } } sta_duration &lt;- unlist(lapply(static_prob, function(x) { as.numeric(difftime(metadata(x)$temporal_extent[2], metadata(x)$temporal_extent[1], units = &quot;days&quot;)) })) m &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() %&gt;% addPolylines(lng = grl$shortest_path$lon, lat = grl$shortest_path$lat, opacity = 1, color = &quot;#808080&quot;, weight = 3) %&gt;% addCircles(lng = grl$shortest_path$lon, lat = grl$shortest_path$lat, opacity = 1, color = &quot;#000&quot;, weight = sta_duration^(0.3) * 10) for (i_s in seq_len(grl$sz[3] - 1)) { if (grl$flight_duration[i_s] &gt; 5) { edge &lt;- which(grl$s == grl$shortest_path$id[i_s] &amp; grl$t == grl$shortest_path$id[i_s + 1]) label &lt;- paste0( i_s, &quot;: &quot;, grl$flight[[i_s]]$start, &quot; - &quot;, grl$flight[[i_s]]$end, &quot;&lt;br&gt;&quot;, &quot;F. dur.: &quot;, round(grl$flight_duration[i_s]), &quot; h &lt;br&gt;&quot;, &quot;GS: &quot;, round(abs(grl$gs[edge])), &quot; km/h, &quot;, fun_NSEW(Arg(grl$gs[edge])), &quot;&lt;br&gt;&quot;, &quot;WS: &quot;, round(abs(grl$ws[edge])), &quot; km/h, &quot;, fun_NSEW(Arg(grl$ws[edge])), &quot;&lt;br&gt;&quot;, &quot;AS: &quot;, round(abs(grl$as[edge])), &quot; km/h, &quot;, fun_NSEW(Arg(grl$as[edge])), &quot;&lt;br&gt;&quot; ) iconArrow &lt;- makeAwesomeIcon( icon = &quot;arrow-up&quot;, library = &quot;fa&quot;, iconColor = &quot;#FFF&quot;, iconRotate = (90 - Arg(grl$ws[edge]) / pi * 180) %% 360, squareMarker = TRUE, markerColor = fun_marker_color(abs(grl$ws[edge])) ) m &lt;- m %&gt;% addAwesomeMarkers( lng = (grl$shortest_path$lon[i_s] + grl$shortest_path$lon[i_s + 1]) / 2, lat = (grl$shortest_path$lat[i_s] + grl$shortest_path$lat[i_s + 1]) / 2, icon = iconArrow, popup = label ) } } 5.6 Output 2: Marginal proability map Same as Basic graph grl_marginal &lt;- graph_marginal(grl) See code for figure li_s &lt;- list() l &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i_r in seq_len(length(grl_marginal))) { i_s &lt;- metadata(static_prob[[i_r]])$sta_id info &lt;- metadata(static_prob[[i_r]])$temporal_extent info_str &lt;- paste0(i_s, &quot; | &quot;, info[1], &quot;-&gt;&quot;, info[2]) li_s &lt;- append(li_s, info_str) l &lt;- l %&gt;% addRasterImage(grl_marginal[[i_r]], colors = &quot;OrRd&quot;, opacity = 0.8, group = info_str) %&gt;% addCircles(lng = grl$shortest_path$lon[i_s], lat = grl$shortest_path$lat[i_s], opacity = 1, color = &quot;#000&quot;, weight = 10, group = info_str) } m &lt;- l %&gt;% addPolylines(lng = grl$shortest_path$lon, lat = grl$shortest_path$lat, opacity = .5, color = &quot;#808080&quot;, weight = 0.5) %&gt;% addCircles(lng = grl$shortest_path$lon, lat = grl$shortest_path$lat, opacity = .5, color = &quot;#000&quot;, weight = sta_duration^(0.3) * 10) %&gt;% addLayersControl( overlayGroups = li_s, options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(tail(li_s, length(li_s) - 1)) 5.7 Output 3: Simulated paths Same as Basic graph nj &lt;- 10 # Number of simulation path_sim &lt;- graph_simulation(grl, nj = nj) 5.8 GeoPressureViz We can also visualize the shortest path and marginal map in GeoPressureViz. First, we need to query the pressure timeserie on the shortest path location. shortest_path &lt;- as.data.frame(grl$shortest_path) shortest_path_timeserie &lt;- geopressure_ts_path(shortest_path, pam$pressure) Then, we need to load a lot of the previous data and aligned them (same stationary period). We finally write the file in your home directory. grl &lt;- readRDS(system.file(&quot;extdata&quot;, &quot;18LX_grl.rda&quot;, package = &quot;GeoPressureR&quot;)) grl_marginal &lt;- readRDS(system.file(&quot;extdata&quot;, &quot;18LX_grl_marginal.rda&quot;, package = &quot;GeoPressureR&quot;)) shortest_path_timeserie &lt;- readRDS(system.file(&quot;extdata&quot;, &quot;18LX_shortest_path_timeserie.rda&quot;, package = &quot;GeoPressureR&quot;)) static_prob &lt;- readRDS(system.file(&quot;extdata&quot;, &quot;18LX_static_prob.rda&quot;, package = &quot;GeoPressureR&quot;)) light_prob &lt;- readRDS(system.file(&quot;extdata&quot;, &quot;18LX_light_prob.rda&quot;, package = &quot;GeoPressureR&quot;)) pressure_prob &lt;- readRDS(system.file(&quot;extdata&quot;, &quot;18LX_pressure_prob.rda&quot;, package = &quot;GeoPressureR&quot;)) sta_marginal &lt;- unlist(lapply(grl_marginal, function(x) raster::metadata(x)$sta_id)) sta_pres &lt;- unlist(lapply(pressure_prob, function(x) raster::metadata(x)$sta_id)) sta_light &lt;- unlist(lapply(light_prob, function(x) raster::metadata(x)$sta_id)) pressure_prob &lt;- pressure_prob[sta_pres %in% sta_marginal] light_prob &lt;- light_prob[sta_light %in% sta_marginal] geopressureviz &lt;- list( pam = pam, static_prob = static_prob, static_prob_marginal = grl_marginal, pressure_prob = pressure_prob, light_prob = light_prob, pressure_timeserie = shortest_path_timeserie ) save(geopressureviz, file = &quot;~/geopressureviz.RData&quot;) And start the app! shiny::runApp(system.file(&quot;geopressureviz&quot;, package = &quot;GeoPressureR&quot;), launch.browser = getOption(&quot;browser&quot;)) 5.9 Compute flight energy We can compute the energy [Joules] expense of each flight for the bird edge &lt;- t(graph_path2edge(path_sim$id, grl)) # Convert airpseed from km/hr to m/s and use the bird constructure earlier to compute the mechanical power [W=J/s] p_mech &lt;- flight_power(abs(grl$as[edge]) * 1000 / 60 / 60, bird = bird) # Convert the power into energy [J] energy &lt;- p_mech * rep(head(grl$flight_duration, -1) * 60 * 60, nj) dim(energy) &lt;- dim(edge) And compare the histogram of ground, wind, airspeed, flight duration and energy for each of the simulation. energy_df &lt;- data.frame( energy = as.vector(energy), as = abs(grl$as[edge]), gs = abs(grl$gs[edge]), ws = abs(grl$ws[edge]), sta_id_s = rep(head(grl$sta_id, -1), nj), sta_id_t = rep(tail(grl$sta_id, -1), nj), flight_duration = rep(head(grl$flight_duration, -1), nj) ) energy_df$name &lt;- paste(energy_df$sta_id_s, energy_df$sta_id_t, sep = &quot;-&quot;) plot1 &lt;- ggplot(energy_df, aes(reorder(name, sta_id_s), gs)) + theme_bw() + geom_boxplot() plot2 &lt;- ggplot(energy_df, aes(reorder(name, sta_id_s), ws)) + theme_bw() + geom_boxplot() plot3 &lt;- ggplot(energy_df, aes(reorder(name, sta_id_s), as)) + theme_bw() + geom_boxplot() plot4 &lt;- ggplot(energy_df, aes(reorder(name, sta_id_s), flight_duration)) + theme_bw() + geom_point() plot5 &lt;- ggplot(energy_df, aes(reorder(name, sta_id_s), energy)) + theme_bw() + geom_boxplot() # grid.arrange(plot1, plot2, plot3, plot4, plot5, nrow=5) subplot(ggplotly(plot1), ggplotly(plot2), ggplotly(plot3), ggplotly(plot4), ggplotly(plot5), nrows = 5, titleY = TRUE) 5.10 Save save( path_sim, shortest_path, static_prob_marginal, shortest_path_timeserie, file = &quot;data/5_wind_graph/18LX_wind_graph.Rdata&quot; ) References "],["labelling-tracks.html", "A Labelling tracks A.1 Labelling principles A.2 Introduction to TRAINSET A.3 Four tests to check labelling A.4 Common challenges and tips to address them A.5 Examples", " A Labelling tracks In this vignette, we explore how to label your track files (activity and pressure) and provide tips to make the exercise more efficient. To see where this exercise fits in with the overall process, see the vignette How to use GeoPressureR. load(&quot;data/1_pressure/18LX_pressure_prob.Rdata&quot;) A.1 Labelling principles Labelling (manually) your tracks is imperative because geopressure requires highly precise and well-defined pressure timeseries of a fixed/constant locoation both in horizontal (geographical: +/- 10-50km) and vertical (altitude: +/- 2m). The procedure involves labelling (1) activity data when the bird is migrating and (2) identifying pressure datapoints to be discarded from the matching exercise. Activity labelling defines stationary periods and flight duration. A stationary periods is defined by period during which the bird is considered static relative to the size of the grid (~10-50km). The start and end of the stationary period is then used to define the pressure timeseries to be matched. Since flight duration is the key input in the movement model, having an accurate flight duration is critical to correctly estimate the distance traveled by the bird between two stationary periods. Pressure labelling allows to eliminate vertical (altitudinal) movement of the bird. The pressure timeseries matching algorithm is sensitive to pressure variation of a few hPa, such that even a altitudinal movement of a couple of meters can throw off the estimation map for short stationary period. Since the reanalysis data to be matched is provided at a single pressure level, we must discard all data points fromt the geolocator pressure data corresponding to a different elevation. Each species’ migration behaviour is so specific that manual editing remains the fastest option. Indeed, small movement corresponding to small change of pressure and high activity can correspond to local movement (birds essentially stays at the same location) or slow migration. Expertise on your bird expected migration style will be essential to correctly label your tracks. Manual editing also provides a sense of what the bird is doing. You will learn how the bird is moving (e.g. long continuous high altitude flight, short flights over multiple days, alternation between short migration flights and stopovers, etc.). It also provides a sense of the uncertainty of your classification, which is useful to understand and interpret your results. That being said, it is still worth starting the manual editing from an automatically labeled timeseries. pam_classify() defines migratory flight when activity is high for a long period. Refer to possible classification methods on the PAMLr manual. pam &lt;- pam_classify(pam, min_duration = 30) trainset_write(pam, pathname = system.file(&quot;extdata&quot;, package = &quot;GeoPressureR&quot;), filename = &quot;18LX_act_pres-labeled-v1.csv&quot;) Finally, labeling is an iterative process where you will need to check the validity of the pressure timeseries at stationary period against the reanalysis data (more on this later). You can expect to spend between 30sec (e.g. Mangrove Kingfisher) to 10min (e.g. Eurasian Nightjar) per track depending on the species’ migrating complexity. A.2 Introduction to TRAINSET We are suggesting to use TRAINSET, a web based graphical tool for labelling time series. You can read more about TRAINSET on www.trainset.geocene.com and on their Github repository. The tool interface is quite intuitive. Start by uploading your .csv file (e.g., 18IC_act_pres.csv). Initial view of TRAINSET after uploading a file A few tips: Keyboard shortcuts can considerably speed up navigation (zoom in/out, move left/right) and labelling (add/remove a label), specifically with SHIFT. Because of the large number of datapoints, keeping a narrow temporal window will avoid your browser from becoming slow or irresponsive. Change the Active Seties and Reference Series depending on what you are labeling but use both timeseries at the same time to figure out what the bird might be doing. Adapt with the y-axis range to each stationary period to properly see the small (but essential) pressure variations which are not visible in the full view TRAINSET offers more flexibility with the label than required: you can add and remove label values (bottom-right of the page). In order for trainset_read() to work, do not change/edit/add any label, simply use the ones offered : TRUE and FALSE. A.3 Four tests to check labelling To improve and evaluate the quality of your labeling, you can use these four tests. A.3.1 Test 1: Duration of stationary periods and flights The first test consists in checking the duration of flights and stationary periods. pam &lt;- trainset_read(pam, pathname = &quot;data/1_pressure/labels/&quot;, filename = &quot;18LX_act_pres-labeled-v1.csv&quot;) pam &lt;- pam_sta(pam) pam$sta$duration &lt;- difftime(pam$sta$end, pam$sta$start, units = &quot;days&quot;) pam$sta$next_flight_duration &lt;- c(difftime(tail(pam$sta$start, length(pam$sta$start) - 1), head(pam$sta$end, length(pam$sta$end) - 1), units = &quot;hours&quot; ), 0) knitr::kable(subset(pam$sta, duration &lt; 0.25 | next_flight_duration &lt; 1)) sta_id start end duration next_flight_duration 7 7 2017-08-30 23:45:00 2017-08-30 23:55:00 0.0069444 days 4.2500000 hours 14 14 2017-09-11 02:45:00 2017-09-11 23:35:00 0.8680556 days 0.7500000 hours 26 26 2018-04-15 14:55:00 2018-04-15 18:50:00 0.1631944 days 0.6666667 hours 27 27 2018-04-15 19:30:00 2018-04-15 20:10:00 0.0277778 days 1.4166667 hours 30 30 2018-04-29 23:35:00 2018-04-29 23:45:00 0.0069444 days 2.8333333 hours 31 31 2018-04-30 02:35:00 2018-04-30 18:40:00 0.6701389 days 0.6666667 hours 32 32 2018-04-30 19:20:00 2018-04-30 19:40:00 0.0138889 days 2.0833333 hours 33 33 2018-04-30 21:45:00 2018-04-30 21:55:00 0.0069444 days 1.0833333 hours 34 34 2018-04-30 23:00:00 2018-04-30 23:10:00 0.0069444 days 0.8333333 hours 35 35 2018-05-01 00:00:00 2018-05-01 00:10:00 0.0069444 days 0.5833333 hours 36 36 2018-05-01 00:45:00 2018-05-01 23:55:00 0.9652778 days 0.0000000 hours Depending on your specific species, you may want to check the activity labelling of short flight (&lt;1-2hr) as well as the activity labelling before and after short stationary periods (&lt;1-10 hours). Note that the last row has a next_flight_duration of 0 because it is the last stationary period. Repeat this test until your are satisfy with the result. A.3.2 Test 2: Pressure timeseries In the second check, we visually inspect that the pressure timeseries of each stationary period are (1) correctly groups and (2) do not includes pressure outliar (altitudinal movement). pam &lt;- trainset_read(pam, pathname = &quot;data/1_pressure/labels/&quot;, filename = &quot;18LX_act_pres-labeled-v2.csv&quot;) pam &lt;- pam_sta(pam) # Set colorscale col &lt;- rep(RColorBrewer::brewer.pal(9, &quot;Set1&quot;), times = ceiling((nrow(pam$sta) + 1) / 9)) col &lt;- col[1:(nrow(pam$sta) + 1)] names(col) &lt;- levels(factor(c(0, pam$sta$sta_id))) pressure_na &lt;- pam$pressure pressure_na$obs[pressure_na$isoutliar | pressure_na$sta_id == 0] &lt;- NA p &lt;- ggplot() + geom_line(data = pam$pressure, aes(x = date, y = obs), col = &quot;grey&quot;) + geom_line(data = pressure_na, aes(x = date, y = obs, col = factor(sta_id))) + geom_point(data = subset(pam$pressure, isoutliar), aes(x = date, y = obs), colour = &quot;black&quot;) + theme_bw() + scale_colour_manual(values = col) + scale_y_continuous(name = &quot;Pressure (hPa)&quot;) ggplotly(p, dynamicTicks = T) %&gt;% layout(showlegend = F) Ploting this figure with Plotly allows you to zoom-in and pan to check all timeseries are correctly grouped. Make sure each stationary period does not include any pressure measurement from flight (e.g. 1-Sep-2017 in the figure above). You might spot some anomalies in the temporal variation of pressure. In some cases, you can already label the pressure timeseries to remove them. A.3.3 Test 3: Pressure timeseries match So far, we have checked that the pressure timeseries are correctly labeled with their respective stationary periods and that they look relatively smooth. At this stage, the timeseries are good enough to be matched with the reanalysis data. The third test consists of comparing the pressure timeseries from the geolocator to ERA5 at the location with the best match. This allows to distinguish bird movements from natural variations in pressure. This is the most difficult step, and multiple iterations will be necessary to achieve the best results. Note that the location with the best match can be wrong for the short stationary periods. But the point of this exercise is to identify vertical movement of the bird and thus the location doesn’t really matter. pam &lt;- trainset_read(pam, pathname = &quot;data/1_pressure/labels/&quot;, filename = &quot;18LX_act_pres-labeled-v3.csv&quot;) pam &lt;- pam_sta(pam) sta_id_keep &lt;- pam$sta$sta_id[difftime(pam$sta$end, pam$sta$start, units = &quot;hours&quot;) &gt; 12] pam$pressure$sta_id[!(pam$pressure$sta_id %in% sta_id_keep)] &lt;- NA message(&quot;Number of stationay period to query: &quot;, length(sta_id_keep)) ## Number of stationay period to query: 27 We can estimate the probability map for each stationary period with the following code. We will cover these fours functions in more details in the vignette Pressure Map. For each stationary period, we locate the best match and query the pressure timeseries with geopressure_ts() at this location. pressure_maps &lt;- geopressure_map(pam$pressure, extent = c(50, -16, 0, 23), scale = 10, max_sample = 100) pressure_prob &lt;- geopressure_prob_map(pressure_maps) path &lt;- geopressure_map2path(pressure_prob) pressure_timeserie &lt;- geopressure_ts_path(path, pam$pressure) We can now look at a similar figure of pressure timeseries, but this time comparing geolocator data with the best match from the reanalysis data. p &lt;- ggplot() + geom_line(data = pam$pressure, aes(x = date, y = obs), colour = &quot;grey&quot;) + geom_point(data = subset(pam$pressure, isoutliar), aes(x = date, y = obs), colour = &quot;black&quot;) + geom_line(data = subset(do.call(&quot;rbind&quot;, pressure_timeserie), sta_id != 0), aes(x = date, y = pressure0, col = factor(sta_id))) + theme_bw() + scale_colour_manual(values = col) + scale_y_continuous(name = &quot;Pressure (hPa)&quot;) ggplotly(p, dynamicTicks = T) %&gt;% layout(showlegend = F) You can use this figure to identify periods where there is a mismatch between the geolocator and ERA5, usually indicative of altitudinal movement of the bird. Depending on the situation, there are mulitple way of labeling this mismatch. In the easier case, the bird simply flew within the same stationary site (&lt;10-50km) for a short time and came back to the same location. In such case, you can simply label out the pressure timeserie during the temporary change of altitude. If the bird changed altitude but never came back to the same elevation, there a different way of solving this. You can either considered that the new altitude is a new stationay period and label the activity data. Otherwise, you can label out the pressure timerise of the shorter period. It is essential that the resulting pressure timeserie matches the ERA5 pressure at everywhere. Matches are usually better for the longer periods. Looking at the activity data during the same period can also help understand what the bird is doing. In this example, removing a few more pressure datapoints can improve the match, especially for short stopover (e.g. 2017-9-11). See below for the final labeled file. pam &lt;- trainset_read(pam, pathname = &quot;data/1_pressure/labels/&quot;, filename = &quot;18LX_act_pres-labeled.csv&quot;) pam &lt;- pam_sta(pam) p &lt;- ggplot() + geom_line(data = pam$pressure, aes(x = date, y = obs), colour = &quot;grey&quot;) + geom_point(data = subset(pam$pressure, isoutliar), aes(x = date, y = obs), colour = &quot;black&quot;) + geom_line(data = subset(do.call(&quot;rbind&quot;, pressure_timeserie), sta_id != 0), aes(x = date, y = pressure0, col = factor(sta_id))) + theme_bw() + theme_bw() + scale_colour_manual(values = col) + scale_y_continuous(name = &quot;Pressure (hPa)&quot;) ggplotly(p, dynamicTicks = T) %&gt;% layout(showlegend = F) A.3.4 Test 4: Histogram of pressure error Finally, you can also look at the histogram of the pressure error (geolocator-ERA5). For long stationary periods (over 5 days), you want to check that there is a single mode in your distribution. Two modes indicate that the bird is spending time at two different altitudes. This is usual when birds have a day site and a night roost at different elevations. You might also want to check the spread of the distribution. This value can guide you in setting the standard deviation parameter s in geopressure_prob_map(). par(mfrow = c(5, 6), mar = c(1, 1, 3, 1)) for (i_r in seq_along(pressure_timeserie)) { if (!is.null(pressure_timeserie[[i_r]])) { i_s &lt;- unique(pressure_timeserie[[i_r]]$sta_id) df3 &lt;- merge(pressure_timeserie[[i_r]], subset(pam$pressure, !isoutliar &amp; sta_id == i_s), by = &quot;date&quot;) df3$error &lt;- df3$pressure0 - df3$obs hist(df3$error, main = i_s, xlab = &quot;&quot;, ylab = &quot;&quot;) abline(v = 0, col = &quot;red&quot;) } } A.4 Common challenges and tips to address them In the following section, we use examples to illustrate common challenges that may be encountered during manual editing, and offer suggestions on how to address them. A.4.1 Outliars during flights due to low bird activity During a flight, single activity measurements can display low activity due to e.g. short gliding flights with no flapping. The automatic labelling of activity with the KNN classifier may mislabel these points as stationary periods, as illustrated in the example below for the night of the 31st of August. A single mislabeled point can incorrectly split the flight into multiple short flights. This error is highlighted with Test #1 described above. However, birds may also display lower activity at the beginning or end of their flight, which is often misclassified, as illustrated in all three nights in the example below and would not be picked up by Test #1. However, if the low activity happens well before the bird reaches the ground, as illustrated in the example below, the low pressure measurement of flight will be included in the stationary period. These error can sometimes be pick-up in Test #2. Yet this is worth checking all flights activity and assess on a case-by-case basis whether this such datapoints should be included in the flight or not. A.4.2 Importance of zooming in before editing outliers Anomalies in a pressure timeseries might not be obvious at first sight. Zooming in to narrower pressure range helps to understand what is happening. In this example, we have a Tawny Pipit breeding near a mine site with a rough topography. While breeding, it looks like it is staying at a relatively constant elevation, but the sudden drop in pressure towards the end indicates that the bird has changed altitude. In such cases, the aim is to discard all pressure datapoints recorded while the bird was at a different altitude. It may not always be obvious to distinguish temporal variation of pressure from when the bird actually changes altitude. We suggest keeping only the datapoints that you are confident with (here, the first part of the timeseries only) and running Test #3. With a long timeseries such as this one, Test #3 will easily pick up the right location and the timeseries that you want to match. You can simply de-select the datapoints at the end of your timeseries that fit the ERA5 green line. For shorter timeseries, you might need several iterations to pick up the correct match. A.4.3 Short stationary halts between flights Interpreting bird behaviour and defining stationary periods can be difficult, for example when birds extend their migration into the day but with lower intensity, such that the end of flight is not clear. In other cases, the bird stops for a couple of hours and then seems to be active again. This could be low-intensity migratory movement, a short break followed by more migratory flight, or landing at the stopover location, but relocating early morning with the light. The question is whether to label these halts as stationary periods or not. Referring to the pressure timeseries can help assess whether the bird changes location. For example, if the low activity is followed by high activity accompanied by pressure change, we can consider that the bird then changed location, and label the low activity as a stationary period. However, the bird may also land and then complete local flights within its stopover location (with very little pressure variation), in which case we want to avoid creating two different stationary periods. Test #3 helps ensure that no local vertical movements took place. A.4.4 Mountainous species Mountainous species display very specific behaviour with regular altitudinal changes. This is very clear with the Ring Ouzel’s timeseries, which displays daily occurring movements, though not regular enough to make the process automatic, and sometimes changing in altitude. At this scale, it is difficult to assess the temporal variation of pressure, both the 790hPa and 900hPa pressure level might work, such that it is difficult to know which points to discard. At this point it can help to zoom out on the time axis to see whether a certain elevation seems most common. Then proceed iteratively to keep only the datapoints at the same elevation. Test #4 is useful to ensure you did not forget any points. The Eurasian Hoopoe presents more of a challenge as it moves continuously throughout the day, showing a more sinosoidal pattern. This is the most challenging case as distinguishing temporal variation from altitudinal change is difficult. Several iterations should lead to a relatively smooth pressure timeseries. Note that in order to estimate the uncertainty correctly for such cases, the standard deviation s should be increased. Thankfully, this behaviour is restricted to its breeding ground. In some cases, finding a single timeseries is impossible, such as for the wintering site of this Ring Ouzel, never returning to the same elevation. In such cases, we discard the entire timeseries and use only the mask of absolute pressure values. Luckily, by definition mountainous species live in specific areas, which restricts possible locations. In this case, based on previous stationary periods we can establish that the bird was in Morocco, and with such low pressure (i.e. high elevation), only the Atlas mountains fit the pressure mask. A.5 Examples #loader { border: 4px solid #f3f3f3; /* Light grey */ border-top: 4px solid #3498db; /* Blue */ border-radius: 50%; width: 12px; height: 12px; animation: spin 2s linear infinite; display: inline-block; vertical-align: top; } @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } } Choose a track: Great Reed Warbler (18IC)Great Reed Warbler (18LX)Tawny Pipit (22BK)Tawny Pipit (22BN)Eurasian Nightjar (22KT)Eurasian Nightjar (24FF)Red-capped Robin-Chat (24TA)Mangrove Kingfisher (24UL)Woodland Kingfisher (16LP)Woodland Kingfisher (20IK)Eurasian Wryneck (22QL)Eurasian Wryneck (22QO)Ring Ouzel (20OA)Ring Ouzel (20OE)Eurasian Hoopoe (16AQ)Eurasian Hoopoe (16DM) View in full screen "],["probability-aggregation.html", "B Probability aggregation B.1 Problem presentation B.2 Gaussian likelihood function B.3 Probability aggregation", " B Probability aggregation At the core of GeoPressure, we try to estimate the position of the bird based on a pressure mismatch of the geolocator and a weather reanalysis dataset (ERA5). A major challenge in this process is the transformation of map of errors (mismatch) into a probability. In this vignette, we will explore this challenge, look at the theory behind it and explore possible solution using Great Reed Warbler (18IC) as an example. B.1 Problem presentation For each stationary period, we estimate the probability of the position \\(\\textbf{x}\\) of the bird based on a pressure timeseries measured by the geolocator \\(P_{gl}[t] \\quad \\forall t \\in [1,\\ldots,n]\\), which in a Bayesian framework can be written as, \\[p(\\textbf{x}\\mid P_{gl}[1],\\ldots,P_{gl}[n]) \\propto p(P_{gl}[1],\\ldots,P_{gl}[n] \\mid \\textbf{x}) p(\\textbf{x}).\\] We are interested here in determining the likelihood term \\(p(P_{gl} \\mid \\textbf{x})\\) which represents the probability of observing the timeseries \\(P_{gl}\\) knowing that the bird is at location \\(\\textbf{x}\\). To quantify this probability, we look at the mismatch between \\(P_{gl}\\) and the pressure timeseries of the ERA5 database \\(P_{ERA5}(\\textbf{x})\\) extracted at location \\(\\textbf{x}\\). We can reformulate the likelihood as as a probability function \\(f\\) of an error term \\(\\varepsilon(\\textbf{x})\\) which measures a distance between \\(P_{gl}\\) and \\(P_{ERA5}(\\textbf{x})\\) \\[p(P_{gl} \\mid \\textbf{x}) = f(\\varepsilon[1],\\ldots,\\varepsilon[n])\\] This formulation of the problem helps us to split our problem in two: first defining an error term \\(\\varepsilon[t]\\) and secondly defining the likelihood function \\(f\\). B.1.1 Error term In most cases, we would expect to measure the error term with a simple difference \\(P_{ERA5}(\\textbf{x})[t]-P_{gl}[t].\\) However, within a ERA5 grid cell of 9-30km, we can expect a wide range of altitude at which the bird can be located. As such any offset between the two timeseries might be due to nothing more than a difference of altitude. To solve this issue, we remove the mean pressure difference, essentially ignoring the absolute value of pressure (and altitude) such that the error term only quantify the mismatch of the temporal variation, \\[\\varepsilon[t] = \\left( P_{ERA5}(\\textbf{x})[t]-P_{gl}[t]\\right) - \\left( \\frac{1}{n}\\sum_{i=1}^{n} P_{ERA5}(\\textbf{x})[i]-P_{gl}[i] \\right) .\\] This way of building the error term has some important consequences. A timeseries of only one datapoint will always yield zero error at all locations, resulting in an equally probable map. As the number of datapoints increases, the error term will become more and more able to distinguish between “good” and “bad” locations. B.1.2 Error term for the Great Reed Warbler Let’s load the data data and filter load(&quot;data/1_pressure/18LX_pressure_prob.Rdata&quot;) sta_id_keep &lt;- pam$sta$sta_id[difftime(pam$sta$end, pam$sta$start, units = &quot;hours&quot;) &gt; 12] pam$pressure$sta_id[!(pam$pressure$sta_id %in% sta_id_keep)] &lt;- NA We are using the GeoPressure API with the geopressure_map() function to measure the mismatch of the pressure series. Because the API can realistically return only a single map per stationary period, it aggregates the error timeseries with the Mean Squared Error (MSE), \\[\\mathit{MSE} = \\frac{1}{n}\\sum_{t=1}^{n} \\varepsilon[t]^2.\\] We can post-process the data to get back some basic metadata, such as the number of datapoints of each stationay period used. We also compute the position with the minimum MSE sta &lt;- data.frame() raster_mse_list &lt;- c() for (i_s in 1:length(pressure_maps)) { # get MSE layer raster_mse_list[[i_s]] &lt;- pressure_maps[[i_s]][[1]] # change 0 (water) in NA raster_mse_list[[i_s]][raster_mse_list[[i_s]] == 0] &lt;- NA # Acess geotiff metadata mt &lt;- raster::metadata(pressure_maps[[i_s]]) mt$start &lt;- mt$extend_sample[1] mt$end &lt;- mt$extend_sample[2] tmp &lt;- as.data.frame(raster_mse_list[[i_s]][[1]], xy = T) mt$lon &lt;- tmp$x[which.min(tmp[, 3])] mt$lat &lt;- tmp$y[which.min(tmp[, 3])] sta &lt;- rbind(sta, as.data.frame(mt[-4])) } knitr::kable(head(sta)) sta_id nb_sample max_sample margin lon lat 1 1099 250 30 16.75 48.75 2 20 250 30 -3.25 27.75 3 14 250 30 17.25 20.25 4 16 250 30 20.75 49.25 5 522 250 30 12.75 41.25 6 14 250 30 0.25 42.75 B.2 Gaussian likelihood function In order to find an appropriate likelihood function, we first need to assume a distribution of the error. The sources of the errors are (1) the sensor measurement error, (2) the ERA5 reanalysis error and (3) the attitudinal movement of the bird during this time. Because we are removing the mean error, we can ignore any long-term errors (e.g., constant temporal error in ERA5 or biases in the geolocator sensor). The figure below shows the error distribution at the known location of equipment and retrieval. They all look close enough to a Gaussian distribution. In the case of the Great Reed Warbler, the standard deviation is around 0.5. s &lt;- 0.5 Therefore, assuming a gaussian distribution of our error, the Gaussian likelkhood of a multivariate normal distribution is given by \\[ f(\\boldsymbol{\\varepsilon})={\\frac {1}{(2\\pi)^{n/2} \\sqrt{\\det(\\boldsymbol{\\Sigma})}}}\\exp \\left(-\\frac{1}{2} \\boldsymbol{\\varepsilon} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\varepsilon} \\right).\\] with the vector notation \\(\\boldsymbol{\\varepsilon }=[\\varepsilon[1],\\ldots,\\varepsilon[n]]\\) and where the covariance matrix \\(\\boldsymbol{\\Sigma}\\) contains the variance of two datapoints \\(\\boldsymbol{\\Sigma}_{t_1,t_2} = \\operatorname {E}[ \\varepsilon[t_1] \\varepsilon[t_2] ]\\). B.2.1 Independance of errors As the covariance is difficult to quantify explicitly, we can first look at the very strong assumption of independance of the error, \\(\\varepsilon_t \\overset{i.i.d.}{\\sim} \\mathcal{N}(0,\\sigma)\\). In this case, the Gaussian likelkhood function \\(f_{ind}\\) is simply the product of the normal probability density function of each error \\(\\varepsilon[t]\\), \\[ f_{ind}(\\boldsymbol{\\varepsilon})=\\prod _{t=1}^{n}f_\\mathcal{N}(\\varepsilon[t])=\\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{n/2}\\exp \\left(-{\\frac {\\sum _{t=1}^{n}\\varepsilon[t]^2}{2\\sigma ^2}}\\right).\\] We can re-write this equation as a function of the MSE \\[ f_{ind}(\\boldsymbol{\\varepsilon})=\\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{n/2}\\exp \\left(-n{\\frac {\\mathit{MSE}}{2\\sigma ^2}}\\right).\\] Using this equation, we can compute the probability for each stationary periods. In the code below, we define a likelihood function f_prob as a function of \\(n\\), \\(\\sigma\\) and the MSE. f_prob &lt;- function(n, s, MSE) { (1 / (2 * pi * s^2))^(n / 2) * exp(-n * MSE / 2 / s^2) } We define a function below to display the MSE and probability for 8 stationary periods based on a likelihood function. This function will be used later to compare with other likelihood function. fun_plot_prob &lt;- function(f_prob, sta, pressure_maps) { raster_prob_list &lt;- c() for (i_s in 1:length(pressure_maps)) { n &lt;- sta$nb_sample[i_s] raster_prob_list[[i_s]] &lt;- f_prob(n, s, raster_mse_list[[i_s]]) } iis &lt;- c(1, 2, 5, 17, 24, 26) sta[iis, ] dl &lt;- 5 par(mfcol = c(2, length(iis)), mar = c(0, 0, 7, 0), mai = c(0, 0, .1, 0)) for (i_s in iis) { plot(raster_mse_list[[i_s]], main = paste0(&quot;MSE|i_s=&quot;, i_s, &quot;|n=&quot;, sta$nb_sample[i_s]), horizontal = TRUE, axes = FALSE, legend.shrink = .8, xlim = c(sta$lon[i_s] - dl, sta$lon[i_s] + dl), ylim = c(sta$lat[i_s] - dl, sta$lat[i_s] + dl) ) points(sta$lon[i_s], sta$lat[i_s]) } for (i_s in iis) { plot(raster_prob_list[[i_s]], main = &quot;Prob&quot;, horizontal = TRUE, axes = FALSE, legend.shrink = .8, xlim = c(sta$lon[i_s] - dl, sta$lon[i_s] + dl), ylim = c(sta$lat[i_s] - dl, sta$lat[i_s] + dl) ) points(sta$lon[i_s], sta$lat[i_s]) } } fun_plot_prob(f_prob, sta, pressure_maps) Assuming independance, the gaussian likelihood transforms the MSE into probability with narrow ranges of uncertaintie. So narrow that for long stationary period (i_s=1 and 17), the enterie map is 0. This comes from the multiplication of probability assumed in the independence case (see equation above). The underlying assuming of the mulitplication operator is the conjunction of probabilities, where aggregating two information is done with the AND operator: \\(P(A~\\text{and}~B) = P(A)\\times P(B)\\). Only the information content overlaping every datapoint of information is kept. B.2.2 Quantification of the errors dependance Ploting the auto-covariance at the calibration site for all the species allow us to see a temporal pattern in the error. For most bird, we can see a clear daily fluctuation which is certainly due to the bird daily movement for commute between feeding and roosting site. The auto-covariance is approaching 0 for all birds, which is expected as we removed the mean value. However, the sill is reached between 6hours and 12 hours depending on birds (Hoopoe doesn’t reach it after 3 days!). Auto-covariance of the error term From this observation, one option would be to construct a covariance matrix based on the auto-covariance. While this would look like the cleanest way of doing it, we have two issues. The first one is the absence of stationarity. Indeed, the auto-covariance amplitude (and potentially shape) is strongly influenced by the vertical displacement of the bird, which is strongly correlated with topography. For instance, the Eurasian Hoopoe has a high variance and large temporal range because it breeds at the feet of the Alps. During the rest of the year, it lives in rather flat area. Therefore, the covariance built from the breeding site would not be appropriate for the other sites. The second issue has to do with the definition of our error term and the different duration of stationary period. B.3 Probability aggregation In the rest of this vignette, we will take a different angle, re-framing the problem differently and exploring other options to compute the likelihood. In the field of probability aggreation, the problem of combining sources of information with overlapping/redundant content is frame as finding a pooling operator \\(F\\) such that, \\[p(\\textbf{x}\\mid \\varepsilon[1],\\ldots,\\varepsilon[n]) \\approx F(p(\\textbf{x} \\mid \\varepsilon[1]) ,\\ldots,p(\\textbf{x} \\mid \\varepsilon[n])),\\] which, with our gaussian assumption, we can written, \\[ F(f(\\varepsilon[1]),\\ldots,f(\\varepsilon[n]))=F(\\boldsymbol{\\varepsilon})\\] B.3.1 Introduction to Log-linear pooling The most popular aggregation function is the log-linear pooling, \\[F(\\boldsymbol{\\varepsilon}) \\propto \\prod_{t=1}^n f(\\varepsilon[t])^{w_t}\\] This equation also relies on the principle of conjuction of probability, but it uses a weight \\(w_t\\) which is related to the new information brought by each additional \\(\\varepsilon[t]\\). Formally, it can be defined by \\[w_t=\\frac{\\ln p(\\varepsilon[t] \\mid \\boldsymbol{x},\\varepsilon[1],\\ldots \\varepsilon[t-1])}{\\ln p(\\varepsilon[t] \\mid \\boldsymbol{x})}.\\] Allard, Comunian, and Renard (2012) is a great resource to learn more about probability aggregation and log linear pooling. The log-linear pooling aggregation simplifies to the case of Gaussian independence when \\(w_t=1\\). We have already explored this case earlier. In the more general case, using the Gaussian probability density function formula, we can write, \\[f(\\varepsilon[t])^{w_t} = \\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{w_t/2}\\exp \\left(-w_t{\\frac {\\varepsilon[t]^2}{2\\sigma ^2}}\\right).\\] As such, if we assume the weight to be constant \\(w_t=w\\), we can rewrite the pooling aggregator as \\[F(\\boldsymbol{\\varepsilon}) \\propto \\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{\\frac{wn}{2}} \\exp \\left(-{\\frac {w}{2\\sigma ^2}}\\sum _{t=1}^{n}\\varepsilon[t]^2\\right),\\] and even write it as a function of the MSE, \\[F(\\boldsymbol{\\varepsilon}) \\propto \\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{\\frac{wn}{2}} \\exp \\left(-{\\frac {wn}{2\\sigma ^2}}\\textit{MSE}\\right).\\] B.3.2 Log-linear pooling, \\(w=1/n\\) An interesting case is if \\(w=1/n\\), so that \\(\\sum_t w_t=1\\). This would simplify the log-linear pooling aggregator to \\[ F(\\boldsymbol{\\varepsilon})={\\frac {1}{\\sigma\\sqrt{2\\pi} }}\\exp \\left(-{\\frac {1}{2\\sigma ^2}\\mathit{MSE}}\\right),\\] which can be interpreted as the Gaussian probability distributions of the MSE. The length of the timeseries \\(n\\) has disappeared from the equation, so that the aggregation dependence only on the mean square of the errors, regardless of how many datapoints. We can try this and see the influence on the probability map. f_prob &lt;- function(n, s, x) { w &lt;- 1 / n (1 / (2 * pi * s^2))^(n * w / 2) * exp(-w * n / 2 / (s^2) * x) } fun_plot_prob(f_prob, sta, pressure_maps) As expected from the disappearance of n, the uncertainty is now completely independent from the duration of the stationary period. This is again obviously not what we want, but it shows the other extreme of the log-linear pooling. B.3.3 Log-linear pooling, \\(w = \\log(n)/n\\) For this study, we chose to use \\(w=\\frac{\\log(n)}{n}\\), which result in the pooling aggregation \\[F(\\boldsymbol{\\varepsilon}) \\propto \\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{\\frac{w\\log(n)}{2}} \\exp \\left(-{\\frac {\\log(n)}{2\\sigma ^2}}\\textit{MSE}\\right).\\] This scheme was designed to minimize the strength of \\(1/n\\) f_prob &lt;- function(n, s, x) { w &lt;- log(n) / n (1 / (2 * pi * s^2))^(n * w / 2) * exp(-w * n / 2 / (s^2) * x) } fun_plot_prob(f_prob, sta, pressure_maps) B.3.4 Validation Validation of uncertainty estimation is relatively difficult, especially when there are only a few datapoints and we assume that the behaviour of the bird might differ between calibration sites (equipement and retrival) and the rest of its journey. In the figure below, some examples of uncertainty estimate are shown. Ideally, we want the colored area to be small (low uncertainty), but when assessing an uncertainty, we also want the red cross to fall within the colored area. That is, if the red cross is too often outside, our estimator is too confident. Furthermore, the shape of the uncertainty can be strongly anisotripic (e.g., hoopoe bottom right) making the distance between the most likely point (blue) and true value (red cross) a poor measure of uncertainty. Uncertainty of pressure mismatch (colorscale) for the equipement period shwoing the true equipement sire (red cross) wihtin the probability map estimated and the most likely value Assessing uncertainty relies on checking that that the red cross is distributed according to each uncertainty shape. A more formal way to quantifiying the uncertainty is of the quantile of the true value \\(q=p(\\boldsymbol{x}\\leq \\boldsymbol{x}_{true})\\), which corresponds to the proability that the variable is less than or equal to the true value. So, if the true value belongs to the distribution, the distribution of its quantile should be uniform. This can be visualize with the empirical cumulative distribution of the quantiles which should fall on the 1:1 line (like a qq-plot). The two extreme cases (\\(w=1\\) and \\(w=1/n\\)) show overconfidence (above the line) and underconfidence (below the line) respectively. Indeed, the distribution of quantile using the \\(w=1/n\\) method shows a lot of quantile values between 0.9-1, which indicates that the true value is within the 90% uncertainty contour (underconfident). The method chosen (\\(w=\\log(n)/n\\)) is doing better than both, but is still in general underconfident. Because the calibration the validation is performed with rather long temporal serie (equipement and retrival), one can expect that the labelisation of pressure is better/easier than for other places. Thus, it seems more appropriate to be slightly underconfident while the method is being developed. The covariance aggregation scheme was implemented by computing the covariance matrix of the multi-variate Gaussian distribution. The covariance function was build using the exact on the variogram of each species. This is, in theory, the more correct method, but it looks too overconfident. Thus we didn’t use it for now. Looking forward, calibration is highly dependant on the local topography and the ability of the bird to move up and down. Manual edition/labeling has also a strong impact. References "],["gridded-gibbs-sampler.html", "C Gridded Gibbs sampler C.1 Introduction and background C.2 Stationary probability C.3 Movement model C.4 Initialize the path C.5 Run the Gibbs sampler C.6 Illustration", " C Gridded Gibbs sampler In this chapter, we present an alternative approach to the graph (see chapter Basic graph) using a Gibb’s sampler. Compared to the graph approach, (1) it is simpler to implement, (2) can be faster in some situation and (3) can solve potential memory issue but (1) is an approximation (MCMC sampler), (2) cannot account for wind data (at least, not easily). The aim is to produce possible migration trajectory of the bird considering the information of (1) light, (2) pressure and (3) flight distance. C.1 Introduction and background Gibb’s sampler is a special case of the Metropolis hasting where each states of the Markov chains is re-sampled iteratively conditional to the others, thus reducing the probability to sample to conditional probability. With the full conditional probability known, it can be sampled exactly, resulting in proposal always accepted in a traditional Metropolis Hasting framework. This approach thus requires to be able to compute the probability map of the position at one stationary period conditional to the previous and next stationary period. In the bird trajectory model, the conditional probability is simple to compute because (1) the static probability part (pressure and light) dependent only the destination position and can easily be pre-computed as a map (see part 1) and (2) the transitional probability (i.e., movement model) is just based on a distance between the departure and destination, which can be computed efficiently on a grid if either the departure or destination is known. We implemented the gridded gibbs approach will the following procedure: 1. Initial the chain with the following path: - Create the path with the highest probability of the static probability (light and pressure) - Use the known equipment/retrieval site for the first and/or last states of the path - For stationary period shorter than 24hours, interpolate the position based on the other position. 2. Loop through the stationary period to produce a new simulated path. For each stationary period, - Compute the probability of the position conditional to the position of the bird at the previous and next stationary period of the current path. This conditional probability is the product of (1) the static probability of pressure and light at the current stationary period, (2) the probability from the movement model based on the position of the previous stationary period and previous flight duration and (3) the probability from the movement model based on the position of the next stationary period and next flight duration (see Figure 7). - Update the current state of the path with the position sampled from to the probability map computed. Illustration of the gridded gibbs sampler for the 6th stationary period of a specific iteration. On one hand, we can compute the static probability based on the combinaison of pressure and light. On the other hand, we can compute the conditional proability of transition based on the position of the previous and next stationary period (green dot). Based on both information, we can sample possible position (small white dots). The gibbs samples presents several advantages compare to traditional MH. First, by accepting all propostion, it is generally faster to run. Second, it is simple to implement and easier to setup as no step size is necessary. Thirdly, it can sample discontinuous probability space easily, thus allowing to “jump” over the sea. However, Gibbs samples remains sensitive to local minimun in the case where consecutive states are correlated. This is typically the case if several short flights follows a long flight (e.g. pre-breeding stopover in Lybia for 18IC inFigure 8). The next flight constrains so much the position, that gibbs sampler cannot explore correctly the space.This could be solved by using a block gibbs sampler, where the position of all stationary periods separated by short flights are re-sampled together. C.2 Stationary probability We already pre-processed the light and pressure data data in the chapter Static map load(&quot;data/3_static/18LX_static_prob.Rdata&quot;) We first normalize the static probability (light and pressure combine) to ensure that the sum of all probabilities on the map is 1. static_prob_n &lt;- lapply(static_prob, function(x) { probt &lt;- raster::as.matrix(x) probt[is.na(probt)] &lt;- 0 probt / sum(probt, na.rm = T) }) Instead of considering all grids cell of the map, we pre-select only the grid cell of each stationary period which are possible according to the static probability . ‘Possible’ is here defined by all grid cells whose cumulative sum of probability is 99%. thr_prob_percentile &lt;- .99 nds_id &lt;- lapply(static_prob_n, function(probi) { # First, compute the threshold of prob corresponding to percentile probis &lt;- sort(probi) id_prob_percentile &lt;- sum(cumsum(probis) &lt;= (1 - thr_prob_percentile)) thr_prob &lt;- probis[id_prob_percentile + 1] # filter the pixels above the threashold nds &lt;- probi &gt;= thr_prob # return which(nds) }) C.3 Movement model In the movement model, we define the function to convert a groundspeed [km/h] to a probability value. We here use a standard gamma distribution. Note that in the graph approach, we use windspeed sot that the movement model is defined on the airspeed. mvt_pdf &lt;- function(x) { dgamma(x, shape = 7, scale = 7) } We pre-compute the position of the center of all grid cell. lat &lt;- seq(raster::ymax(static_prob[[1]]), raster::ymin(static_prob[[1]]), length.out = nrow(static_prob[[1]]) + 1) lat &lt;- lat[seq_len(length(lat) - 1)] + diff(lat[1:2]) / 2 lon &lt;- seq(raster::xmin(static_prob[[1]]), raster::xmax(static_prob[[1]]), length.out = ncol(static_prob[[1]]) + 1) lon &lt;- lon[seq_len(length(lon) - 1)] + diff(lon[1:2]) / 2 latlon &lt;- expand.grid(lat = lat, lon = lon) Extract the flight duration from the metadata of the static_prob raster data. flight_duration &lt;- unlist(lapply(static_prob, function(x) { mtf &lt;- metadata(x) as.numeric(sum(difftime(mtf$flight$end, mtf$flight$start, units = &quot;hours&quot;))) })) Create a function which compute the distance from a point pt to all other location of the grid id and return the probability that the bird flew these distances at a particular stationary period i_s. prob_mvt &lt;- function(pt, i_s, id) { gs &lt;- geosphere::distGeo(latlon[pt, ], latlon[id, ]) / 1000 / flight_duration[i_s] mvt_pdf(gs) } C.4 Initialize the path As any Metropolis-hasting, we need to provide an initial path to the sampler. Before that, let’s set a few constant nj &lt;- 100 # number of iteration/samples nsta &lt;- length(static_prob) # number of stationary period nll &lt;- dim(static_prob[[1]])[1:2] # number of grid cell Initialize the first path with the most likely position of each stationary period. Yet the position is unlikely to be reliable for short stationary period. To fix this, we will linearly interpolate the position of short stationary period. We first identify and remove the position of short stationary period (1 day). path &lt;- matrix(ncol = nsta, nrow = nj) path[1, ] &lt;- geopressure_map2path(static_prob, interp = 1, format = &quot;ind&quot;)$ind Then, we set the position of the first and last stationary period (equipment and retrieval) for all simulated path. path[, 1] &lt;- which(as.matrix(static_prob[[1]]) == 1) path[, nsta] &lt;- which(as.matrix(static_prob[[nsta]]) == 1) Visualize the initial path path_ll &lt;- arrayInd(path[1, ], nll) leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() %&gt;% addPolylines(lng = lon[path_ll[, 2]], lat = lat[path_ll[, 1]], opacity = 1, color = &quot;#808080&quot;, weight = 3) %&gt;% addCircles(lng = lon[path_ll[, 2]], lat = lat[path_ll[, 1]], opacity = 1, color = &quot;#000&quot;, weight = 10) We can set/get the stationary period to simulate ss &lt;- which(is.na(path[2, ])) C.5 Run the Gibbs sampler Now that all the preparation are done, we can perform the simulation by simply iterating through nj for (j in seq(from = 2, to = nj)) { # Looping through the stationay period to simulate for (i_s in ss) { # get the probability from the position of the current path for the previous stationary period to all possible location of the current stationary period prob_prev &lt;- prob_mvt(path[j, i_s - 1], i_s - 1, nds_id[[i_s]]) # get the probability from all possible location of the current stationary period to the position of the previous path for the next stationary period prob_next &lt;- prob_mvt(path[j - 1, i_s + 1], i_s, nds_id[[i_s]]) # Compute the probability as the product of the static probability and the dynamic probability prob &lt;- static_prob_n[[i_s]][nds_id[[i_s]]] * prob_next * prob_prev # Ransom sample a position according to the proability computed path[j, i_s] &lt;- nds_id[[i_s]][sum(stats::runif(1) &gt; cumsum(prob) / sum(prob)) + 1] } } C.6 Illustration Illustration of the simulation with 10 paths m &lt;- leaflet(width = &quot;100%&quot;) %&gt;% leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i in seq(from = 50, to = nj, length.out = 10)) { path_ll &lt;- arrayInd(path[i, ], nll) m &lt;- m %&gt;% addPolylines(lng = lon[path_ll[, 2]], lat = lat[path_ll[, 1]], opacity = 0.7, weight = 1, color = &quot;#808080&quot;) %&gt;% addCircles(lng = lon[path_ll[, 2]], lat = lat[path_ll[, 1]], opacity = 1, weight = 1, color = &quot;#000&quot;) } m Compare the simulated position of each stationary period with the corresponding static probability. li_s &lt;- list() l &lt;- leaflet(width = &quot;100%&quot;) %&gt;% addProviderTiles(providers$Stamen.TerrainBackground) %&gt;% addFullscreenControl() for (i_r in seq_len(length(static_prob))) { i_s &lt;- metadata(static_prob[[i_r]])$sta_id info &lt;- metadata(static_prob[[i_r]])$extend_sample info_str &lt;- paste0(i_s, &quot; | &quot;, info[1], &quot;-&gt;&quot;, info[2]) li_s &lt;- append(li_s, info_str) path_ll &lt;- arrayInd(path[, i_r], nll) l &lt;- l %&gt;% addRasterImage(static_prob[[i_r]], opacity = 0.8, colors = &quot;OrRd&quot;, group = info_str) %&gt;% addCircles(lng = lon[path_ll[, 2]], lat = lat[path_ll[, 1]], opacity = .1, color = &quot;#000&quot;, group = info_str) } l %&gt;% addLayersControl( overlayGroups = li_s, options = layersControlOptions(collapsed = FALSE) ) %&gt;% hideGroup(tail(li_s, length(li_s) - 1)) "],["resources.html", "D Resources D.1 Publications D.2 Presentations D.3 Projects using GeoPressureR", " D Resources D.1 Publications Raphaël Nussbaumer, Mathieu Gravey, Martins Briedis, Felix Liechti. Global positioning with animal-borne pressure sensors, 14 June 2022, PREPRINT (Version 2) available at Research Square https://doi.org/10.21203/rs.3.rs-1381915/v2 Raphaël Nussbaumer, Mathieu Gravey, Martins Briedis, Felix Liechti. Inferring bird’s trajectory from multi-sensor geolocators and remote sensing with a graphical model, 25 May 2022, PREPRINT (Version 1) available at Research Square https://doi.org/10.21203/rs.3.rs-1693751/v1 D.2 Presentations Raphaël Nussbaumer, Mathieu Gravey, Martins Briedis, Felix Liechti. Leveraging light, pressure, activity, and wind data to improve geolocator positioning. August 2022. 28th International Ornithological Congress. PRESENTATION available at Youtube. Raphaël Nussbaumer, Mathieu Gravey, Felix Liechti. Improving the spatial accuracy of multi-sensor geolocators’ position using atmospheric surface pressure. October 2021. 7th International Bio-logging Science Symposium. PRESENTATION available at Youtube. D.3 Projects using GeoPressureR List of all research projects using GeoPressureR with links to the code used to analyse and create figures. This might be helpful to get an idea of how to analyse your data and borrow some code sections for your own project. Feel free to contact me if you’d like to appear on this list. Species GeoPressureTemplate/code Publication/status Mongolian Nightjar Rafnuss/MongolianNightjar Lathouwers et al. (2022) Woodland Kingfisher Rafnuss/WoodlandKingfisher Osinubi et al. (in prep.) Northern Wheatear Rafnuss/Val-Piora-Wheatear Rime et al. (in prep.) Red-capped Robin-chat and Mangrove Kingfisher Rafnuss/MK-RCRC collecting data Swainson’s Warbler grhyne/SWWA_Pressure "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
